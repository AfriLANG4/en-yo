{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "jw300_bpe_en-xh_masakhane.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "l929HimrxS0a",
        "YkuK3B4p2AkN",
        "epeCydmCyS8X",
        "AaE77Tcppex9"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AfriLANG4/masakhane/blob/master/jw300_bpe_en_xh_masakhane.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Igc5itf-xMGj"
      },
      "source": [
        "# Masakhane - Machine Translation for African Languages (Using JoeyNMT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "x4fXCKCf36IK"
      },
      "source": [
        "## Note before beginning:\n",
        "### - The idea is that you should be able to make minimal changes to this in order to get SOME result for your own translation corpus. \n",
        "\n",
        "### - The tl;dr: Go to the **\"TODO\"** comments which will tell you what to update to get up and running\n",
        "\n",
        "### - If you actually want to have a clue what you're doing, read the text and peek at the links\n",
        "\n",
        "### - With 100 epochs, it should take around 7 hours to run in Google Colab\n",
        "\n",
        "### - Once you've gotten a result for your language, please attach and email your notebook that generated it to masakhanetranslation@gmail.com\n",
        "\n",
        "### - If you care enough and get a chance, doing a brief background on your language would be amazing. See examples in  [(Martinus, 2019)](https://arxiv.org/abs/1906.05685)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "l929HimrxS0a"
      },
      "source": [
        "## Retrieve your data & make a parallel corpus\n",
        "\n",
        "If you are wanting to use the JW300 data referenced on the Masakhane website or in our GitHub repo, you can use `opus-tools` to convert the data into a convenient format. `opus_read` from that package provides a convenient tool for reading the native aligned XML files and to convert them to TMX format. The tool can also be used to fetch relevant files from OPUS on the fly and to filter the data as necessary. [Read the documentation](https://pypi.org/project/opustools-pkg/) for more details.\n",
        "\n",
        "Once you have your corpus files in TMX format (an xml structure which will include the sentences in your target language and your source language in a single file), we recommend reading them into a pandas dataframe. Thankfully, Jade wrote a silly `tmx2dataframe` package which converts your tmx file to a pandas dataframe. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oGRmDELn7Az0",
        "outputId": "6d47cee0-ae7e-4111-ea3d-2a7414b52ea9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Cn3tgQLzUxwn",
        "colab": {}
      },
      "source": [
        "# TODO: Set your source and target languages. Keep in mind, these traditionally use language codes as found here:\n",
        "# These will also become the suffix's of all vocab and corpus files used throughout\n",
        "import os\n",
        "source_language = \"en\"\n",
        "target_language = \"xh\" \n",
        "lc = False  # If True, lowercase the data.\n",
        "seed = 42  # Random seed for shuffling.\n",
        "tag = \"baseline\" # Give a unique name to your folder - this is to ensure you don't rewrite any models you've already submitted\n",
        "\n",
        "os.environ[\"src\"] = source_language # Sets them in bash as well, since we often use bash scripts\n",
        "os.environ[\"tgt\"] = target_language\n",
        "os.environ[\"tag\"] = tag\n",
        "\n",
        "# This will save it to a folder in our gdrive instead!\n",
        "!mkdir -p \"/content/drive/My Drive/masakhane/$src-$tgt-$tag\"\n",
        "os.environ[\"gdrive_path\"] = \"/content/drive/My Drive/masakhane/%s-%s-%s\" % (source_language, target_language, tag)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kBSgJHEw7Nvx",
        "outputId": "bf3748a5-5501-4377-b953-9b8451011d47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!echo $gdrive_path"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/masakhane/en-xh-baseline\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gA75Fs9ys8Y9",
        "outputId": "63b67f77-14ac-4f03-f9ff-3827240f92b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "# Install opus-tools\n",
        "! pip install opustools-pkg"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting opustools-pkg\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/9f/e829a0cceccc603450cd18e1ff80807b6237a88d9a8df2c0bb320796e900/opustools_pkg-0.0.52-py3-none-any.whl (80kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 2.3MB/s \n",
            "\u001b[?25hInstalling collected packages: opustools-pkg\n",
            "Successfully installed opustools-pkg-0.0.52\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xq-tDZVks7ZD",
        "outputId": "2cafbf3e-d100-490b-aaab-bb3b3d87f241",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        }
      },
      "source": [
        "# Downloading our corpus\n",
        "! opus_read -d JW300 -s $src -t $tgt -wm moses -w jw300.$src jw300.$tgt -q\n",
        "\n",
        "# extract the corpus file\n",
        "! gunzip JW300_latest_xml_$src-$tgt.xml.gz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Alignment file /proj/nlpl/data/OPUS/JW300/latest/xml/en-xh.xml.gz not found. The following files are available for downloading:\n",
            "\n",
            "   7 MB https://object.pouta.csc.fi/OPUS-JW300/v1/xml/en-xh.xml.gz\n",
            " 263 MB https://object.pouta.csc.fi/OPUS-JW300/v1/xml/en.zip\n",
            "  78 MB https://object.pouta.csc.fi/OPUS-JW300/v1/xml/xh.zip\n",
            "\n",
            " 348 MB Total size\n",
            "./JW300_latest_xml_en-xh.xml.gz ... 100% of 7 MB\n",
            "./JW300_latest_xml_en.zip ... 100% of 263 MB\n",
            "./JW300_latest_xml_xh.zip ... 100% of 78 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n48GDRnP8y2G",
        "colab_type": "code",
        "outputId": "fe6be555-8fb4-4011-c883-d8ca7a01d48c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        }
      },
      "source": [
        "# Download the global test set.\n",
        "! wget https://raw.githubusercontent.com/juliakreutzer/masakhane/master/jw300_utils/test/test.en-any.en\n",
        "  \n",
        "# And the specific test set for this language pair.\n",
        "os.environ[\"trg\"] = target_language \n",
        "os.environ[\"src\"] = source_language \n",
        "\n",
        "! wget https://raw.githubusercontent.com/juliakreutzer/masakhane/master/jw300_utils/test/test.en-$trg.en \n",
        "! mv test.en-$trg.en test.en\n",
        "! wget https://raw.githubusercontent.com/juliakreutzer/masakhane/master/jw300_utils/test/test.en-$trg.$trg \n",
        "! mv test.en-$trg.$trg test.$trg"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-28 02:54:46--  https://raw.githubusercontent.com/juliakreutzer/masakhane/master/jw300_utils/test/test.en-any.en\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 277791 (271K) [text/plain]\n",
            "Saving to: ‘test.en-any.en’\n",
            "\n",
            "\rtest.en-any.en        0%[                    ]       0  --.-KB/s               \rtest.en-any.en      100%[===================>] 271.28K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2019-11-28 02:54:46 (5.39 MB/s) - ‘test.en-any.en’ saved [277791/277791]\n",
            "\n",
            "--2019-11-28 02:54:49--  https://raw.githubusercontent.com/juliakreutzer/masakhane/master/jw300_utils/test/test.en-xh.en\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 206162 (201K) [text/plain]\n",
            "Saving to: ‘test.en-xh.en’\n",
            "\n",
            "test.en-xh.en       100%[===================>] 201.33K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2019-11-28 02:54:51 (5.30 MB/s) - ‘test.en-xh.en’ saved [206162/206162]\n",
            "\n",
            "--2019-11-28 02:54:56--  https://raw.githubusercontent.com/juliakreutzer/masakhane/master/jw300_utils/test/test.en-xh.xh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 211374 (206K) [text/plain]\n",
            "Saving to: ‘test.en-xh.xh’\n",
            "\n",
            "test.en-xh.xh       100%[===================>] 206.42K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2019-11-28 02:54:56 (5.44 MB/s) - ‘test.en-xh.xh’ saved [211374/211374]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqDG-CI28y2L",
        "colab_type": "code",
        "outputId": "88dc414f-4760-4f58-b4fc-3c784ee701e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Read the test data to filter from train and dev splits.\n",
        "# Store english portion in set for quick filtering checks.\n",
        "en_test_sents = set()\n",
        "filter_test_sents = \"test.en-any.en\"\n",
        "j = 0\n",
        "with open(filter_test_sents) as f:\n",
        "  for line in f:\n",
        "    en_test_sents.add(line.strip())\n",
        "    j += 1\n",
        "print('Loaded {} global test sentences to filter from the training/dev data.'.format(j))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 3571 global test sentences to filter from the training/dev data.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3CNdwLBCfSIl",
        "outputId": "80144d4c-bd97-4ccc-b7c6-2e08ab08b0d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# TMX file to dataframe\n",
        "source_file = 'jw300.' + source_language\n",
        "target_file = 'jw300.' + target_language\n",
        "\n",
        "source = []\n",
        "target = []\n",
        "skip_lines = []  # Collect the line numbers of the source portion to skip the same lines for the target portion.\n",
        "with open(source_file) as f:\n",
        "    for i, line in enumerate(f):\n",
        "        # Skip sentences that are contained in the test set.\n",
        "        if line.strip() not in en_test_sents:\n",
        "            source.append(line.strip())\n",
        "        else:\n",
        "            skip_lines.append(i)             \n",
        "with open(target_file) as f:\n",
        "    for j, line in enumerate(f):\n",
        "        # Only add to corpus if corresponding source was not skipped.\n",
        "        if j not in skip_lines:\n",
        "            target.append(line.strip())\n",
        "    \n",
        "print('Loaded data and skipped {}/{} lines since contained in test set.'.format(len(skip_lines), i))\n",
        "    \n",
        "df = pd.DataFrame(zip(source, target), columns=['source_sentence', 'target_sentence'])\n",
        "# if you get TypeError: data argument can't be an iterator is because of your zip version run this below\n",
        "#df = pd.DataFrame(list(zip(source, target)), columns=['source_sentence', 'target_sentence'])\n",
        "df.head(3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded data and skipped 7158/876188 lines since contained in test set.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source_sentence</th>\n",
              "      <th>target_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How One Marriage Was Saved</td>\n",
              "      <td>Indlela Owasindiswa Ngayo Lo Mtshato</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>“ The application of the counsel in the book M...</td>\n",
              "      <td>Omnye umfundi onoxabiso nowaseMzantsi Afrika w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>“ Chapter 5 , ‘ A Wife Who Is Dearly Loved , ’...</td>\n",
              "      <td>“ Isahluko 5 , esithi ‘ Umfazi Othandwa Kunene...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     source_sentence                                    target_sentence\n",
              "0                         How One Marriage Was Saved               Indlela Owasindiswa Ngayo Lo Mtshato\n",
              "1  “ The application of the counsel in the book M...  Omnye umfundi onoxabiso nowaseMzantsi Afrika w...\n",
              "2  “ Chapter 5 , ‘ A Wife Who Is Dearly Loved , ’...  “ Isahluko 5 , esithi ‘ Umfazi Othandwa Kunene..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNRsoCmoaNMP",
        "colab_type": "code",
        "outputId": "be2d1312-5851-44c2-8183-06d6e67c5af1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "df[df.duplicated()]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source_sentence</th>\n",
              "      <th>target_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>202</th>\n",
              "      <td>But how ?</td>\n",
              "      <td>Kodwa njani ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>352</th>\n",
              "      <td>“ The application of the counsel in the book M...</td>\n",
              "      <td>Omnye umfundi onoxabiso nowaseMzantsi Afrika w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>353</th>\n",
              "      <td>“ Chapter 5 , ‘ A Wife Who Is Dearly Loved , ’...</td>\n",
              "      <td>“ Isahluko 5 , esithi ‘ Umfazi Othandwa Kunene...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>354</th>\n",
              "      <td>I never imagined in my wildest dreams that I c...</td>\n",
              "      <td>Andizange ndicinge nasephupheni ukuba ndandise...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>355</th>\n",
              "      <td>Thank you very , very much .</td>\n",
              "      <td>Enkosi kakhulu .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>868827</th>\n",
              "      <td>MEMORIAL ATTENDANCE ( 2015 )</td>\n",
              "      <td>ABEZE ESIKHUMBUZWENI ( 2015 )</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>868828</th>\n",
              "      <td>This publication is not for sale .</td>\n",
              "      <td>Le magazini ayithengiswa .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>868857</th>\n",
              "      <td>Jesus said : “ ‘ You must love Jehovah your Go...</td>\n",
              "      <td>UYesu wathi : “ ‘ Uze umthande uYehova uThixo ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>868984</th>\n",
              "      <td>Why ?</td>\n",
              "      <td>Ngoba ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>868994</th>\n",
              "      <td>What about us ?</td>\n",
              "      <td>Kuthekani ngathi ?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>51516 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          source_sentence                                    target_sentence\n",
              "202                                             But how ?                                      Kodwa njani ?\n",
              "352     “ The application of the counsel in the book M...  Omnye umfundi onoxabiso nowaseMzantsi Afrika w...\n",
              "353     “ Chapter 5 , ‘ A Wife Who Is Dearly Loved , ’...  “ Isahluko 5 , esithi ‘ Umfazi Othandwa Kunene...\n",
              "354     I never imagined in my wildest dreams that I c...  Andizange ndicinge nasephupheni ukuba ndandise...\n",
              "355                          Thank you very , very much .                                   Enkosi kakhulu .\n",
              "...                                                   ...                                                ...\n",
              "868827                       MEMORIAL ATTENDANCE ( 2015 )                      ABEZE ESIKHUMBUZWENI ( 2015 )\n",
              "868828                 This publication is not for sale .                         Le magazini ayithengiswa .\n",
              "868857  Jesus said : “ ‘ You must love Jehovah your Go...  UYesu wathi : “ ‘ Uze umthande uYehova uThixo ...\n",
              "868984                                              Why ?                                            Ngoba ?\n",
              "868994                                    What about us ?                                 Kuthekani ngathi ?\n",
              "\n",
              "[51516 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YkuK3B4p2AkN"
      },
      "source": [
        "## Pre-processing and export\n",
        "\n",
        "It is generally a good idea to remove duplicate translations and conflicting translations from the corpus. In practice, these public corpora include some number of these that need to be cleaned.\n",
        "\n",
        "In addition we will split our data into dev/test/train and export to the filesystem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heJUDAAVaqLj",
        "colab_type": "code",
        "outputId": "f40b9a4d-2c7e-4082-fd7a-a00cf7b118f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(\"Length of Data before Removing duplicate: \",len(df))\n",
        "df = df.drop_duplicates()\n",
        "print(\"Length of Data after Removing duplicate: \",len(df))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of Data before Removing duplicate:  869031\n",
            "Length of Data after Removing duplicate:  817515\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hxxBOCA-xXhy",
        "outputId": "cdf72cbe-7bdb-4393-c9ee-b9ca4d2036d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# This section does the split between train/dev for the parallel corpora then saves them as separate files\n",
        "# We use 1000 dev test and the given test set.\n",
        "import csv\n",
        "\n",
        "# Do the split between dev/train and create parallel corpora\n",
        "num_dev_patterns = 1000\n",
        "\n",
        "# Optional: lower case the corpora - this will make it easier to generalize, but without proper casing.\n",
        "if lc:  # Julia: making lowercasing optional\n",
        "    df[\"source_sentence\"] = df[\"source_sentence\"].str.lower()\n",
        "    df[\"target_sentence\"] = df[\"target_sentence\"].str.lower()\n",
        "\n",
        "# Julia: test sets are already generated\n",
        "dev = df.tail(num_dev_patterns) # Herman: Error in original\n",
        "stripped = df.drop(df.tail(num_dev_patterns).index)\n",
        "\n",
        "with open(\"train.\"+source_language, \"w\") as src_file, open(\"train.\"+target_language, \"w\") as trg_file:\n",
        "  for index, row in stripped.iterrows():\n",
        "    src_file.write(row[\"source_sentence\"]+\"\\n\")\n",
        "    trg_file.write(row[\"target_sentence\"]+\"\\n\")\n",
        "    \n",
        "with open(\"dev.\"+source_language, \"w\") as src_file, open(\"dev.\"+target_language, \"w\") as trg_file:\n",
        "  for index, row in dev.iterrows():\n",
        "    src_file.write(row[\"source_sentence\"]+\"\\n\")\n",
        "    trg_file.write(row[\"target_sentence\"]+\"\\n\")\n",
        "\n",
        "#stripped[[\"source_sentence\"]].to_csv(\"train.\"+source_language, header=False, index=False)  # Herman: Added `header=False` everywhere\n",
        "#stripped[[\"target_sentence\"]].to_csv(\"train.\"+target_language, header=False, index=False)  # Julia: Problematic handling of quotation marks.\n",
        "\n",
        "#dev[[\"source_sentence\"]].to_csv(\"dev.\"+source_language, header=False, index=False)\n",
        "#dev[[\"target_sentence\"]].to_csv(\"dev.\"+target_language, header=False, index=False)\n",
        "\n",
        "\n",
        "# Doublecheck the format below. There should be no extra quotation marks or weird characters.\n",
        "! head train.*\n",
        "! head dev.*\n",
        "! head test.*"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> train.en <==\n",
            "How One Marriage Was Saved\n",
            "“ The application of the counsel in the book Making Your Family Life Happy saved my marriage , ” wrote an appreciative reader from South Africa .\n",
            "“ Chapter 5 , ‘ A Wife Who Is Dearly Loved , ’ opened my eyes .\n",
            "I never imagined in my wildest dreams that I could unwittingly cause so many problems .\n",
            "Thank you very , very much .\n",
            "My marriage had been in the most stormy parts of the sea , and now , after months , it is back in the quiet harbour of happiness . ”\n",
            "If you desire help in making your marriage a happier one , you can benefit from this book .\n",
            "Receive a copy by filling in and mailing the coupon .\n",
            "Please send , postpaid , the hardcover , 192 - page book Making Your Family Life Happy .\n",
            "I enclose $ 1 ( U.S . ) .\n",
            "\n",
            "==> train.xh <==\n",
            "Indlela Owasindiswa Ngayo Lo Mtshato\n",
            "Omnye umfundi onoxabiso nowaseMzantsi Afrika wabhala wenjenje : “ Ukusebenzisa isiluleko esikwincwadi ethi Ukwenza Ubomi Bentsapho Yakho Bonwabe kwawusindisa umtshato wam . ”\n",
            "“ Isahluko 5 , esithi ‘ Umfazi Othandwa Kunene , ’ sawavula amehlo am .\n",
            "Andizange ndicinge nasephupheni ukuba ndandisenokuthi ngempazamo ndibangele iingxaki ezininzi kangaka .\n",
            "Enkosi kakhulu .\n",
            "Umtshato wam ubukweyona meko imbi gqitha , yaye ngoku , emva kweenyanga nje ezimbalwa , uphinde wabuyela ekubeni ngumtshato owonwabisayo . ”\n",
            "Ukuba unqwenela uncedo ekwenzeni umtshato wakho ube ngowonwabisayo , unokungenelwa yile ncwadi .\n",
            "Zifumanele umbhalo wakho ngokuzalisa uze uthumele eli phetshana .\n",
            "Ncedani nindithumelele , iposi ihlawulelwe , incwadi eneqweqwe elilukhuni , nenamaphepha ali - 192 ethi Ukwenza Ubomi Bentsapho Yakho Bonwabe .\n",
            "Ndithumela ii - R2,50 .\n",
            "==> dev.en <==\n",
            "Because we love the Bible , we also love our publications , which are based on God’s Word .\n",
            "All the books , brochures , magazines , and other literature we receive are provisions from Jehovah .\n",
            "They help us to stay close to him and to keep our faith strong . ​ — Titus 2 : 2 .\n",
            "Many of our publications are written for Jehovah’s Witnesses in general .\n",
            "However , there are some publications that are written for specific groups , such as young ones or parents .\n",
            "Most of the articles and videos on our website are prepared specifically for people who are not Jehovah’s Witnesses .\n",
            "Such a variety of material shows that Jehovah has kept his promise to provide plenty of instruction for all people . ​ — Isaiah 25 : 6 .\n",
            "Most of us would like to have more time to read the Bible and our publications .\n",
            "So we may not always spend the same amount of time studying every publication we get .\n",
            "We can be sure that Jehovah is pleased with us when we use our time wisely to read and study the Bible and our publications .\n",
            "\n",
            "==> dev.xh <==\n",
            "Ngenxa yokuba siyithanda iBhayibhile , siyazithanda neencwadi zethu , ezisekelwe kwiLizwi likaThixo .\n",
            "Zonke iincwadi , iincwadana , iimagazini nolunye uncwadi esilufumanayo , ngamalungiselelo avela kuYehova .\n",
            "Zisinceda sihlale sisondelelene naye , yaye sigcine ukholo lwethu lomelele . — Tito 2 : 2 .\n",
            "Uninzi lweencwadi zethu lubhalelwe amaNgqina kaYehova .\n",
            "Sekunjalo , kukho iincwadi ezibhalelwe ngokukhethekileyo amaqela athile , njengolutsha okanye abazali .\n",
            "Uninzi lwamanqaku neevidiyo ezikwiwebhsayithi yethu , zilungiselelwe ngokukhethekileyo abantu abangengawo amaNgqina kaYehova .\n",
            "Ubukho bezi zixhobo zahlukahlukeneyo bubungqina bokuba uYehova uye wasigcina isithembiso sakhe sokubanika ulwalathiso bonke abantu . — Isaya 25 : 6 .\n",
            "Uninzi lwethu lungathanda ukuchitha ixesha elingakumbi lufundisisa iBhayibhile neencwadi zethu .\n",
            "Ngoko liyohluka ixesha esilichitha sifundisisa uncwadi ngalunye esilufumanayo .\n",
            "Sinokuqiniseka ukuba uYehova uyavuya xa silisebenzisa kakuhle ixesha lethu ngokufundisisa iBhayibhile nezinye iincwadi zethu .\n",
            "==> test.en <==\n",
            "Jesus said : “ You must love your neighbor as yourself . ”\n",
            "For day and night your hand was heavy upon me . ”\n",
            "Some of the names in this article have been changed .\n",
            "Some names in this article have been changed .\n",
            "This is the greatest and first commandment . ”\n",
            "It does not belong to man who is walking even to direct his step . ”\n",
            "“ The whole world is lying in the power of the wicked one . ”\n",
            "Published by Jehovah’s Witnesses but now out of print .\n",
            "Moreover , do not call anyone your father on earth , for one is your Father , the heavenly One .\n",
            "I am going to make a helper for him , as a complement of him . ”\n",
            "\n",
            "==> test.en-any.en <==\n",
            "10 , 11 . ( a ) How common is divorce ?\n",
            "10 , 11 . ( a ) How does Satan try to cause us to let our hands drop down ?\n",
            "10 , 11 . ( a ) In what sense is our worship of Jehovah exclusive ?\n",
            "10 , 11 . ( a ) Of what must we be careful , and why ?\n",
            "10 , 11 . ( a ) What injustices did Joseph experience ?\n",
            "10 , 11 . ( a ) When reading the qualifications for elders , how can we apply the information in our own life ?\n",
            "10 , 11 . ( a ) Why is jealousy dangerous ?\n",
            "10 - 12 . ( a ) How did Jesus cultivate the interest others showed in the good news ?\n",
            "11 , 12 . ( a ) After he sinned , what could David not do ?\n",
            "11 , 12 . ( a ) A person who is thinking about getting baptized needs to be sure of what ?\n",
            "\n",
            "==> test.xh <==\n",
            "UYesu wathi : “ Uze umthande ummelwane wakho njengoko uzithanda ngako . ”\n",
            "Ngokuba imini nobusuku , besinzima phezu kwam isandla sakho . ”\n",
            "Wambi amagama akweli nqaku aguquliwe .\n",
            "Wambi amagama kweli nqaku atshintshiwe .\n",
            "Lo ngowona myalelo mkhulu nowokuqala . ”\n",
            "Asikokomntu ohambayo ukwalathisa inyathelo lakhe . ”\n",
            "“ Ihlabathi liphela lisemandleni ongendawo . ”\n",
            "Ipapashwe ngamaNgqina kaYehova kodwa ngoku ayisashicilelwa .\n",
            "Ngaphezu koko , ningabizi nabani na ngokuthi nguyihlo emhlabeni , kuba mnye uYihlo , Lowo wasezulwini .\n",
            "Ndiza kumenzela umncedi oza kuba ngumphelelisi wakhe . ”\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXbSRu0VwlKq",
        "colab_type": "code",
        "outputId": "4076b471-0068-49d4-fd63-b7e245e9c2ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "! cat train.en | wc -l\n",
        "! cat train.xh | wc -l\n",
        "! cat dev.en | wc -l\n",
        "! cat dev.xh | wc -l\n",
        "! cat test.en | wc -l\n",
        "! cat test.xh | wc -l"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "816515\n",
            "816515\n",
            "1000\n",
            "1000\n",
            "2717\n",
            "2717\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "epeCydmCyS8X"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Installation of JoeyNMT\n",
        "\n",
        "JoeyNMT is a simple, minimalist NMT package which is useful for learning and teaching. Check out the documentation for JoeyNMT [here](https://joeynmt.readthedocs.io)  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iBRMm4kMxZ8L",
        "outputId": "10e03a47-1bdd-4be8-a4f3-44c832595b19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Install JoeyNMT\n",
        "! git clone https://github.com/joeynmt/joeynmt.git\n",
        "! cd joeynmt; pip3 install ."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'joeynmt'...\n",
            "remote: Enumerating objects: 15, done.\u001b[K\n",
            "remote: Counting objects:   6% (1/15)\u001b[K\rremote: Counting objects:  13% (2/15)\u001b[K\rremote: Counting objects:  20% (3/15)\u001b[K\rremote: Counting objects:  26% (4/15)\u001b[K\rremote: Counting objects:  33% (5/15)\u001b[K\rremote: Counting objects:  40% (6/15)\u001b[K\rremote: Counting objects:  46% (7/15)\u001b[K\rremote: Counting objects:  53% (8/15)\u001b[K\rremote: Counting objects:  60% (9/15)\u001b[K\rremote: Counting objects:  66% (10/15)\u001b[K\rremote: Counting objects:  73% (11/15)\u001b[K\rremote: Counting objects:  80% (12/15)\u001b[K\rremote: Counting objects:  86% (13/15)\u001b[K\rremote: Counting objects:  93% (14/15)\u001b[K\rremote: Counting objects: 100% (15/15)\u001b[K\rremote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 2199 (delta 4), reused 5 (delta 3), pack-reused 2184\u001b[K\n",
            "Receiving objects: 100% (2199/2199), 2.60 MiB | 2.80 MiB/s, done.\n",
            "Resolving deltas: 100% (1525/1525), done.\n",
            "Processing /content/joeynmt\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (0.16.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (4.3.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (1.17.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (41.6.0)\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (1.3.1)\n",
            "Requirement already satisfied: tensorflow>=1.14 in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (1.15.0)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (0.3.1)\n",
            "Collecting sacrebleu>=1.3.6\n",
            "  Downloading https://files.pythonhosted.org/packages/0e/e5/93d252182f7cbd4b59bb3ec5797e2ce33cfd6f5aadaf327db170cf4b7887/sacrebleu-1.4.2-py3-none-any.whl\n",
            "Collecting subword-nmt\n",
            "  Downloading https://files.pythonhosted.org/packages/74/60/6600a7bc09e7ab38bc53a48a20d8cae49b837f93f5842a41fe513a694912/subword_nmt-0.3.7-py2.py3-none-any.whl\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (3.1.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (0.9.0)\n",
            "Collecting pyyaml>=5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/e8/b3212641ee2718d556df0f23f78de8303f068fe29cdaa7a91018849582fe/PyYAML-5.1.2.tar.gz (265kB)\n",
            "\u001b[K     |████████████████████████████████| 266kB 7.9MB/s \n",
            "\u001b[?25hCollecting pylint\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/59/43fc36c5ee316bb9aeb7cf5329cdbdca89e5749c34d5602753827c0aa2dc/pylint-2.4.4-py3-none-any.whl (302kB)\n",
            "\u001b[K     |████████████████████████████████| 307kB 42.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: six==1.12 in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (1.12.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->joeynmt==0.0.1) (0.46)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (1.0.8)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (3.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (1.1.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (0.2.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (1.11.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (0.8.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (0.1.8)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (0.33.6)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (1.15.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (0.8.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (3.10.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext->joeynmt==0.0.1) (4.28.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext->joeynmt==0.0.1) (2.21.0)\n",
            "Collecting portalocker\n",
            "  Downloading https://files.pythonhosted.org/packages/91/db/7bc703c0760df726839e0699b7f78a4d8217fdc9c7fcb1b51b39c5a22a4e/portalocker-1.5.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from sacrebleu>=1.3.6->joeynmt==0.0.1) (3.6.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->joeynmt==0.0.1) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->joeynmt==0.0.1) (2.4.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->joeynmt==0.0.1) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->joeynmt==0.0.1) (2.6.1)\n",
            "Requirement already satisfied: pandas>=0.15.2 in /usr/local/lib/python3.6/dist-packages (from seaborn->joeynmt==0.0.1) (0.25.3)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from seaborn->joeynmt==0.0.1) (1.3.2)\n",
            "Collecting astroid<2.4,>=2.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/ae/86734823047962e7b8c8529186a1ac4a7ca19aaf1aa0c7713c022ef593fd/astroid-2.3.3-py3-none-any.whl (205kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 44.3MB/s \n",
            "\u001b[?25hCollecting mccabe<0.7,>=0.6\n",
            "  Downloading https://files.pythonhosted.org/packages/87/89/479dc97e18549e21354893e4ee4ef36db1d237534982482c3681ee6e7b57/mccabe-0.6.1-py2.py3-none-any.whl\n",
            "Collecting isort<5,>=4.2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/b0/c121fd1fa3419ea9bfd55c7f9c4fedfec5143208d8c7ad3ce3db6c623c21/isort-4.3.21-py2.py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow>=1.14->joeynmt==0.0.1) (2.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow>=1.14->joeynmt==0.0.1) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow>=1.14->joeynmt==0.0.1) (0.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->joeynmt==0.0.1) (2019.9.11)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->joeynmt==0.0.1) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->joeynmt==0.0.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->joeynmt==0.0.1) (3.0.4)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.15.2->seaborn->joeynmt==0.0.1) (2018.9)\n",
            "Collecting typed-ast<1.5,>=1.4.0; implementation_name == \"cpython\" and python_version < \"3.8\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/31/d3/9d1802c161626d0278bafb1ffb32f76b9d01e123881bbf9d91e8ccf28e18/typed_ast-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (736kB)\n",
            "\u001b[K     |████████████████████████████████| 737kB 44.4MB/s \n",
            "\u001b[?25hCollecting lazy-object-proxy==1.4.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0b/dd/b1e3407e9e6913cf178e506cd0dee818e58694d9a5cd1984e3f6a8b9a10f/lazy_object_proxy-1.4.3-cp36-cp36m-manylinux1_x86_64.whl (55kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.5MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: joeynmt, pyyaml\n",
            "  Building wheel for joeynmt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for joeynmt: filename=joeynmt-0.0.1-cp36-none-any.whl size=72136 sha256=f89096f6dc4b35697dc6609bc1739a621f9e13a0ecf58ad0e963439e575bc81b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-49iy698r/wheels/db/01/db/751cc9f3e7f6faec127c43644ba250a3ea7ad200594aeda70a\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.1.2-cp36-cp36m-linux_x86_64.whl size=44104 sha256=357da8d77f9d8c15bd8f7ea1d8cc2df424f11fb8eccf15864e225a0255897b69\n",
            "  Stored in directory: /root/.cache/pip/wheels/d9/45/dd/65f0b38450c47cf7e5312883deb97d065e030c5cca0a365030\n",
            "Successfully built joeynmt pyyaml\n",
            "Installing collected packages: portalocker, sacrebleu, subword-nmt, pyyaml, typed-ast, lazy-object-proxy, astroid, mccabe, isort, pylint, joeynmt\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed astroid-2.3.3 isort-4.3.21 joeynmt-0.0.1 lazy-object-proxy-1.4.3 mccabe-0.6.1 portalocker-1.5.2 pylint-2.4.4 pyyaml-5.1.2 sacrebleu-1.4.2 subword-nmt-0.3.7 typed-ast-1.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AaE77Tcppex9"
      },
      "source": [
        "# Preprocessing the Data into Subword BPE Tokens\n",
        "\n",
        "- One of the most powerful improvements for agglutinative languages (a feature of most Bantu languages) is using BPE tokenization [ (Sennrich, 2015) ](https://arxiv.org/abs/1508.07909).\n",
        "\n",
        "- It was also shown that by optimizing the umber of BPE codes we significantly improve results for low-resourced languages [(Sennrich, 2019)](https://www.aclweb.org/anthology/P19-1021) [(Martinus, 2019)](https://arxiv.org/abs/1906.05685)\n",
        "\n",
        "- Below we have the scripts for doing BPE tokenization of our data. We use 4000 tokens as recommended by [(Sennrich, 2019)](https://www.aclweb.org/anthology/P19-1021). You do not need to change anything. Simply running the below will be suitable. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H-TyjtmXB1mL",
        "outputId": "2df785e8-17f4-4553-8fa2-913f396342c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "# One of the huge boosts in NMT performance was to use a different method of tokenizing. \n",
        "# Usually, NMT would tokenize by words. However, using a method called BPE gave amazing boosts to performance\n",
        "\n",
        "# Do subword NMT\n",
        "from os import path\n",
        "os.environ[\"src\"] = source_language # Sets them in bash as well, since we often use bash scripts\n",
        "os.environ[\"tgt\"] = target_language\n",
        "\n",
        "# Learn BPEs on the training data.\n",
        "os.environ[\"data_path\"] = path.join(\"joeynmt\", \"data\", source_language + target_language) # Herman! \n",
        "! subword-nmt learn-joint-bpe-and-vocab --input train.$src train.$tgt -s 4000 -o bpe.codes.4000 --write-vocabulary vocab.$src vocab.$tgt\n",
        "\n",
        "# Apply BPE splits to the development and test data.\n",
        "! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$src < train.$src > train.bpe.$src\n",
        "! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$tgt < train.$tgt > train.bpe.$tgt\n",
        "\n",
        "! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$src < dev.$src > dev.bpe.$src\n",
        "! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$tgt < dev.$tgt > dev.bpe.$tgt\n",
        "! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$src < test.$src > test.bpe.$src\n",
        "! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$tgt < test.$tgt > test.bpe.$tgt\n",
        "\n",
        "# Create directory, move everyone we care about to the correct location\n",
        "! mkdir -p $data_path\n",
        "! cp train.* $data_path\n",
        "! cp test.* $data_path\n",
        "! cp dev.* $data_path\n",
        "\n",
        "! cp bpe.codes.4000 $data_path\n",
        "! ls $data_path\n",
        "\n",
        "# Also move everything we care about to a mounted location in google drive (relevant if running in colab) at gdrive_path\n",
        "! cp train.* \"$gdrive_path\"\n",
        "! cp test.* \"$gdrive_path\"\n",
        "! cp dev.* \"$gdrive_path\"\n",
        "! cp bpe.codes.4000 \"$gdrive_path\"\n",
        "! ls \"$gdrive_path\"\n",
        "\n",
        "# Create that vocab using build_vocab\n",
        "! sudo chmod 777 joeynmt/scripts/build_vocab.py\n",
        "! joeynmt/scripts/build_vocab.py joeynmt/data/$src$tgt/train.bpe.$src joeynmt/data/$src$tgt/train.bpe.$tgt --output_path joeynmt/data/$src$tgt/vocab.txt\n",
        "\n",
        "# Some output\n",
        "! echo \"BPE Yoruba Sentences\"\n",
        "! tail -n 5 test.bpe.$tgt\n",
        "! echo \"Combined BPE Vocab\"\n",
        "! tail -n 10 joeynmt/data/$src$tgt/vocab.txt  # Herman"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bpe.codes.4000\tdev.en\t     test.bpe.xh     test.xh\t   train.en\n",
            "dev.bpe.en\tdev.xh\t     test.en\t     train.bpe.en  train.xh\n",
            "dev.bpe.xh\ttest.bpe.en  test.en-any.en  train.bpe.xh\n",
            "bpe.codes.4000\tdev.en\t     test.bpe.xh     test.xh\t   train.en\n",
            "dev.bpe.en\tdev.xh\t     test.en\t     train.bpe.en  train.xh\n",
            "dev.bpe.xh\ttest.bpe.en  test.en-any.en  train.bpe.xh\n",
            "BPE Yoruba Sentences\n",
            "Oku kwa@@ ph@@ umela ekubeni nd@@ id@@ ume njengom@@ ntu ong@@ any@@ anis@@ ekanga .\n",
            "Xa nd@@ afunda inyaniso , and@@ izange nd@@ iph@@ inde nd@@ iv@@ ume ukuq@@ hubeka ndis@@ enza oko , naku@@ beni ndand@@ ihl@@ awul@@ wa um@@ v@@ uzo on@@ c@@ um@@ isayo .\n",
            "Nd@@ ing@@ umzekelo om@@ hle ko@@ onyana bam abab@@ ini yaye nd@@ iye nd@@ af@@ anel@@ ekela amalung@@ elo ang@@ akumbi ebandleni .\n",
            "Nd@@ az@@ iwa njengom@@ ntu on@@ yanisekileyo ngabantu end@@ ish@@ ish@@ ina kunye nabo kwan@@ abahl@@ ol@@ i boku@@ m@@ a kwem@@ ali ye@@ enk@@ amp@@ ani ( t@@ a@@ x a@@ ud@@ it@@ ors ) . ”\n",
            "U@@ R@@ ute wa@@ f@@ ud@@ ukela kwa@@ Sirayeli apho way@@ eza ku@@ kwazi uku@@ nq@@ ula oy@@ ena Thixo w@@ okwenyaniso .\n",
            "Combined BPE Vocab\n",
            "anekiso\n",
            ";@@\n",
            "¥\n",
            "Í\n",
            "–@@\n",
            "Ù@@\n",
            "!@@\n",
            "Ο@@\n",
            "?@@\n",
            "ź@@\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IlMitUHR8Qy-",
        "outputId": "64a02980-14b4-414a-a34e-0744cb0d273d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# Also move everything we care about to a mounted location in google drive (relevant if running in colab) at gdrive_path\n",
        "! cp train.* \"$gdrive_path\"\n",
        "! cp test.* \"$gdrive_path\"\n",
        "! cp dev.* \"$gdrive_path\"\n",
        "! cp bpe.codes.4000 \"$gdrive_path\"\n",
        "! ls \"$gdrive_path\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bpe.codes.4000\tdev.en\t     test.bpe.xh     test.xh\t   train.en\n",
            "dev.bpe.en\tdev.xh\t     test.en\t     train.bpe.en  train.xh\n",
            "dev.bpe.xh\ttest.bpe.en  test.en-any.en  train.bpe.xh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ixmzi60WsUZ8"
      },
      "source": [
        "# Creating the JoeyNMT Config\n",
        "\n",
        "JoeyNMT requires a yaml config. We provide a template below. We've also set a number of defaults with it, that you may play with!\n",
        "\n",
        "- We used Transformer architecture \n",
        "- We set our dropout to reasonably high: 0.3 (recommended in  [(Sennrich, 2019)](https://www.aclweb.org/anthology/P19-1021))\n",
        "\n",
        "Things worth playing with:\n",
        "- The batch size (also recommended to change for low-resourced languages)\n",
        "- The number of epochs (we've set it at 30 just so it runs in about an hour, for testing purposes)\n",
        "- The decoder options (beam_size, alpha)\n",
        "- Evaluation metrics (BLEU versus Crhf4)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PIs1lY2hxMsl",
        "colab": {}
      },
      "source": [
        "# This creates the config file for our JoeyNMT system. It might seem overwhelming so we've provided a couple of useful parameters you'll need to update\n",
        "# (You can of course play with all the parameters if you'd like!)\n",
        "\n",
        "name = '%s%s' % (source_language, target_language)\n",
        "gdrive_path = os.environ[\"gdrive_path\"]\n",
        "\n",
        "# Create the config\n",
        "config = \"\"\"\n",
        "name: \"{name}_transformer\"\n",
        "\n",
        "data:\n",
        "    src: \"{source_language}\"\n",
        "    trg: \"{target_language}\"\n",
        "    train: \"data/{name}/train.bpe\"\n",
        "    dev:   \"data/{name}/dev.bpe\"\n",
        "    test:  \"data/{name}/test.bpe\"\n",
        "    level: \"bpe\"\n",
        "    lowercase: False\n",
        "    max_sent_length: 100\n",
        "    src_vocab: \"data/{name}/vocab.txt\"\n",
        "    trg_vocab: \"data/{name}/vocab.txt\"\n",
        "\n",
        "testing:\n",
        "    beam_size: 5\n",
        "    alpha: 1.0\n",
        "\n",
        "training:\n",
        "    #load_model: \"{gdrive_path}/models/{name}_transformer/1.ckpt\" # if uncommented, load a pre-trained model from this checkpoint\n",
        "    random_seed: 42\n",
        "    optimizer: \"adam\"\n",
        "    normalization: \"tokens\"\n",
        "    adam_betas: [0.9, 0.999] \n",
        "    scheduling: \"plateau\"           # TODO: try switching from plateau to Noam scheduling\n",
        "    patience: 5                     # For plateau: decrease learning rate by decrease_factor if validation score has not improved for this many validation rounds.\n",
        "    learning_rate_factor: 0.5       # factor for Noam scheduler (used with Transformer)\n",
        "    learning_rate_warmup: 1000      # warmup steps for Noam scheduler (used with Transformer)\n",
        "    decrease_factor: 0.7\n",
        "    loss: \"crossentropy\"\n",
        "    learning_rate: 0.0003\n",
        "    learning_rate_min: 0.00000001\n",
        "    weight_decay: 0.0\n",
        "    label_smoothing: 0.1\n",
        "    batch_size: 4096\n",
        "    batch_type: \"token\"\n",
        "    eval_batch_size: 3600\n",
        "    eval_batch_type: \"token\"\n",
        "    batch_multiplier: 1\n",
        "    early_stopping_metric: \"ppl\"\n",
        "    epochs: 50                     # TODO: Decrease for when playing around and checking of working. Around 30 is sufficient to check if its working at all\n",
        "    validation_freq: 1000          # TODO: Set to at least once per epoch.\n",
        "    logging_freq: 100\n",
        "    eval_metric: \"bleu\"\n",
        "    model_dir: \"models/{name}_transformer\"\n",
        "    overwrite: False               # TODO: Set to True if you want to overwrite possibly existing models. \n",
        "    shuffle: True\n",
        "    use_cuda: True\n",
        "    max_output_length: 100\n",
        "    print_valid_sents: [0, 1, 2, 3]\n",
        "    keep_last_ckpts: 3\n",
        "\n",
        "model:\n",
        "    initializer: \"xavier\"\n",
        "    bias_initializer: \"zeros\"\n",
        "    init_gain: 1.0\n",
        "    embed_initializer: \"xavier\"\n",
        "    embed_init_gain: 1.0\n",
        "    tied_embeddings: True\n",
        "    tied_softmax: True\n",
        "    encoder:\n",
        "        type: \"transformer\"\n",
        "        num_layers: 6\n",
        "        num_heads: 4             # TODO: Increase to 8 for larger data.\n",
        "        embeddings:\n",
        "            embedding_dim: 256   # TODO: Increase to 512 for larger data.\n",
        "            scale: True\n",
        "            dropout: 0.2\n",
        "        # typically ff_size = 4 x hidden_size\n",
        "        hidden_size: 256         # TODO: Increase to 512 for larger data.\n",
        "        ff_size: 1024            # TODO: Increase to 2048 for larger data.\n",
        "        dropout: 0.3\n",
        "    decoder:\n",
        "        type: \"transformer\"\n",
        "        num_layers: 6\n",
        "        num_heads: 4              # TODO: Increase to 8 for larger data.\n",
        "        embeddings:\n",
        "            embedding_dim: 256    # TODO: Increase to 512 for larger data.\n",
        "            scale: True\n",
        "            dropout: 0.2\n",
        "        # typically ff_size = 4 x hidden_size\n",
        "        hidden_size: 256         # TODO: Increase to 512 for larger data.\n",
        "        ff_size: 1024            # TODO: Increase to 2048 for larger data.\n",
        "        dropout: 0.3\n",
        "\"\"\".format(name=name, gdrive_path=os.environ[\"gdrive_path\"], source_language=source_language, target_language=target_language)\n",
        "with open(\"joeynmt/configs/transformer_{name}.yaml\".format(name=name),'w') as f:\n",
        "    f.write(config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzJtuvwCOl4H",
        "colab_type": "text"
      },
      "source": [
        "#*Tensorboard*\n",
        "JoeyNMT additionally uses TensorboardX to visualize training and validation curves and attention matrices during training. Launch Tensorboard (requires installation that is not included in JoeyNMTs requirements) like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoBJrURfqWFP",
        "colab_type": "code",
        "outputId": "31f58077-7412-47b5-cf9d-1908167fef19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Restart runtime using 'Runtime' -> 'Restart runtime...'\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4Z8QObHNUhi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FX0-6G05Osnl",
        "colab_type": "code",
        "outputId": "8c168e57-d6bf-43e5-f3c6-ebd5137e7d90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "%tensorboard --logdir \"$gdrive_path/models/enxh_transformer/tensorboard\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div id=\"root\"></div>\n",
              "    <script>\n",
              "      (function() {\n",
              "        window.TENSORBOARD_ENV = window.TENSORBOARD_ENV || {};\n",
              "        window.TENSORBOARD_ENV[\"IN_COLAB\"] = true;\n",
              "        document.querySelector(\"base\").href = \"https://localhost:6006\";\n",
              "        function fixUpTensorboard(root) {\n",
              "          const tftb = root.querySelector(\"tf-tensorboard\");\n",
              "          // Disable the fragment manipulation behavior in Colab. Not\n",
              "          // only is the behavior not useful (as the iframe's location\n",
              "          // is not visible to the user), it causes TensorBoard's usage\n",
              "          // of `window.replace` to navigate away from the page and to\n",
              "          // the `localhost:<port>` URL specified by the base URI, which\n",
              "          // in turn causes the frame to (likely) crash.\n",
              "          tftb.removeAttribute(\"use-hash\");\n",
              "        }\n",
              "        function executeAllScripts(root) {\n",
              "          // When `script` elements are inserted into the DOM by\n",
              "          // assigning to an element's `innerHTML`, the scripts are not\n",
              "          // executed. Thus, we manually re-insert these scripts so that\n",
              "          // TensorBoard can initialize itself.\n",
              "          for (const script of root.querySelectorAll(\"script\")) {\n",
              "            const newScript = document.createElement(\"script\");\n",
              "            newScript.type = script.type;\n",
              "            newScript.textContent = script.textContent;\n",
              "            root.appendChild(newScript);\n",
              "            script.remove();\n",
              "          }\n",
              "        }\n",
              "        function setHeight(root, height) {\n",
              "          // We set the height dynamically after the TensorBoard UI has\n",
              "          // been initialized. This avoids an intermediate state in\n",
              "          // which the container plus the UI become taller than the\n",
              "          // final width and cause the Colab output frame to be\n",
              "          // permanently resized, eventually leading to an empty\n",
              "          // vertical gap below the TensorBoard UI. It's not clear\n",
              "          // exactly what causes this problematic intermediate state,\n",
              "          // but setting the height late seems to fix it.\n",
              "          root.style.height = `${height}px`;\n",
              "        }\n",
              "        const root = document.getElementById(\"root\");\n",
              "        fetch(\".\")\n",
              "          .then((x) => x.text())\n",
              "          .then((html) => void (root.innerHTML = html))\n",
              "          .then(() => fixUpTensorboard(root))\n",
              "          .then(() => executeAllScripts(root))\n",
              "          .then(() => setHeight(root, 800));\n",
              "      })();\n",
              "    </script>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pIifxE3Qzuvs"
      },
      "source": [
        "# Train the Model\n",
        "\n",
        "This single line of joeynmt runs the training using the config we made above"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6ZBPFwT94WpI",
        "colab": {}
      },
      "source": [
        "# # Train the model\n",
        "# # You can press Ctrl-C to stop. And then run the next cell to save your checkpoints! \n",
        "# !cd joeynmt; python3 -m joeynmt train configs/transformer_$src$tgt.yaml"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntqWYE3oMEoN",
        "colab_type": "code",
        "outputId": "32a5c4e9-4686-425a-9480-2fdbc5d134a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Train the model\n",
        "# You can press Ctrl-C to stop. And then run the next cell to save your checkpoints! \n",
        "!cd joeynmt; python3 -m joeynmt train configs/transformer_$src$tgt.yaml"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-11-28 03:28:33,220 Hello! This is Joey-NMT.\n",
            "2019-11-28 03:28:36,730 Total params: 12201984\n",
            "2019-11-28 03:28:36,731 Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.layers.2.dec_layer_norm.bias', 'decoder.layers.2.dec_layer_norm.weight', 'decoder.layers.2.feed_forward.layer_norm.bias', 'decoder.layers.2.feed_forward.layer_norm.weight', 'decoder.layers.2.feed_forward.pwff_layer.0.bias', 'decoder.layers.2.feed_forward.pwff_layer.0.weight', 'decoder.layers.2.feed_forward.pwff_layer.3.bias', 'decoder.layers.2.feed_forward.pwff_layer.3.weight', 'decoder.layers.2.src_trg_att.k_layer.bias', 'decoder.layers.2.src_trg_att.k_layer.weight', 'decoder.layers.2.src_trg_att.output_layer.bias', 'decoder.layers.2.src_trg_att.output_layer.weight', 'decoder.layers.2.src_trg_att.q_layer.bias', 'decoder.layers.2.src_trg_att.q_layer.weight', 'decoder.layers.2.src_trg_att.v_layer.bias', 'decoder.layers.2.src_trg_att.v_layer.weight', 'decoder.layers.2.trg_trg_att.k_layer.bias', 'decoder.layers.2.trg_trg_att.k_layer.weight', 'decoder.layers.2.trg_trg_att.output_layer.bias', 'decoder.layers.2.trg_trg_att.output_layer.weight', 'decoder.layers.2.trg_trg_att.q_layer.bias', 'decoder.layers.2.trg_trg_att.q_layer.weight', 'decoder.layers.2.trg_trg_att.v_layer.bias', 'decoder.layers.2.trg_trg_att.v_layer.weight', 'decoder.layers.2.x_layer_norm.bias', 'decoder.layers.2.x_layer_norm.weight', 'decoder.layers.3.dec_layer_norm.bias', 'decoder.layers.3.dec_layer_norm.weight', 'decoder.layers.3.feed_forward.layer_norm.bias', 'decoder.layers.3.feed_forward.layer_norm.weight', 'decoder.layers.3.feed_forward.pwff_layer.0.bias', 'decoder.layers.3.feed_forward.pwff_layer.0.weight', 'decoder.layers.3.feed_forward.pwff_layer.3.bias', 'decoder.layers.3.feed_forward.pwff_layer.3.weight', 'decoder.layers.3.src_trg_att.k_layer.bias', 'decoder.layers.3.src_trg_att.k_layer.weight', 'decoder.layers.3.src_trg_att.output_layer.bias', 'decoder.layers.3.src_trg_att.output_layer.weight', 'decoder.layers.3.src_trg_att.q_layer.bias', 'decoder.layers.3.src_trg_att.q_layer.weight', 'decoder.layers.3.src_trg_att.v_layer.bias', 'decoder.layers.3.src_trg_att.v_layer.weight', 'decoder.layers.3.trg_trg_att.k_layer.bias', 'decoder.layers.3.trg_trg_att.k_layer.weight', 'decoder.layers.3.trg_trg_att.output_layer.bias', 'decoder.layers.3.trg_trg_att.output_layer.weight', 'decoder.layers.3.trg_trg_att.q_layer.bias', 'decoder.layers.3.trg_trg_att.q_layer.weight', 'decoder.layers.3.trg_trg_att.v_layer.bias', 'decoder.layers.3.trg_trg_att.v_layer.weight', 'decoder.layers.3.x_layer_norm.bias', 'decoder.layers.3.x_layer_norm.weight', 'decoder.layers.4.dec_layer_norm.bias', 'decoder.layers.4.dec_layer_norm.weight', 'decoder.layers.4.feed_forward.layer_norm.bias', 'decoder.layers.4.feed_forward.layer_norm.weight', 'decoder.layers.4.feed_forward.pwff_layer.0.bias', 'decoder.layers.4.feed_forward.pwff_layer.0.weight', 'decoder.layers.4.feed_forward.pwff_layer.3.bias', 'decoder.layers.4.feed_forward.pwff_layer.3.weight', 'decoder.layers.4.src_trg_att.k_layer.bias', 'decoder.layers.4.src_trg_att.k_layer.weight', 'decoder.layers.4.src_trg_att.output_layer.bias', 'decoder.layers.4.src_trg_att.output_layer.weight', 'decoder.layers.4.src_trg_att.q_layer.bias', 'decoder.layers.4.src_trg_att.q_layer.weight', 'decoder.layers.4.src_trg_att.v_layer.bias', 'decoder.layers.4.src_trg_att.v_layer.weight', 'decoder.layers.4.trg_trg_att.k_layer.bias', 'decoder.layers.4.trg_trg_att.k_layer.weight', 'decoder.layers.4.trg_trg_att.output_layer.bias', 'decoder.layers.4.trg_trg_att.output_layer.weight', 'decoder.layers.4.trg_trg_att.q_layer.bias', 'decoder.layers.4.trg_trg_att.q_layer.weight', 'decoder.layers.4.trg_trg_att.v_layer.bias', 'decoder.layers.4.trg_trg_att.v_layer.weight', 'decoder.layers.4.x_layer_norm.bias', 'decoder.layers.4.x_layer_norm.weight', 'decoder.layers.5.dec_layer_norm.bias', 'decoder.layers.5.dec_layer_norm.weight', 'decoder.layers.5.feed_forward.layer_norm.bias', 'decoder.layers.5.feed_forward.layer_norm.weight', 'decoder.layers.5.feed_forward.pwff_layer.0.bias', 'decoder.layers.5.feed_forward.pwff_layer.0.weight', 'decoder.layers.5.feed_forward.pwff_layer.3.bias', 'decoder.layers.5.feed_forward.pwff_layer.3.weight', 'decoder.layers.5.src_trg_att.k_layer.bias', 'decoder.layers.5.src_trg_att.k_layer.weight', 'decoder.layers.5.src_trg_att.output_layer.bias', 'decoder.layers.5.src_trg_att.output_layer.weight', 'decoder.layers.5.src_trg_att.q_layer.bias', 'decoder.layers.5.src_trg_att.q_layer.weight', 'decoder.layers.5.src_trg_att.v_layer.bias', 'decoder.layers.5.src_trg_att.v_layer.weight', 'decoder.layers.5.trg_trg_att.k_layer.bias', 'decoder.layers.5.trg_trg_att.k_layer.weight', 'decoder.layers.5.trg_trg_att.output_layer.bias', 'decoder.layers.5.trg_trg_att.output_layer.weight', 'decoder.layers.5.trg_trg_att.q_layer.bias', 'decoder.layers.5.trg_trg_att.q_layer.weight', 'decoder.layers.5.trg_trg_att.v_layer.bias', 'decoder.layers.5.trg_trg_att.v_layer.weight', 'decoder.layers.5.x_layer_norm.bias', 'decoder.layers.5.x_layer_norm.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'encoder.layers.4.feed_forward.layer_norm.bias', 'encoder.layers.4.feed_forward.layer_norm.weight', 'encoder.layers.4.feed_forward.pwff_layer.0.bias', 'encoder.layers.4.feed_forward.pwff_layer.0.weight', 'encoder.layers.4.feed_forward.pwff_layer.3.bias', 'encoder.layers.4.feed_forward.pwff_layer.3.weight', 'encoder.layers.4.layer_norm.bias', 'encoder.layers.4.layer_norm.weight', 'encoder.layers.4.src_src_att.k_layer.bias', 'encoder.layers.4.src_src_att.k_layer.weight', 'encoder.layers.4.src_src_att.output_layer.bias', 'encoder.layers.4.src_src_att.output_layer.weight', 'encoder.layers.4.src_src_att.q_layer.bias', 'encoder.layers.4.src_src_att.q_layer.weight', 'encoder.layers.4.src_src_att.v_layer.bias', 'encoder.layers.4.src_src_att.v_layer.weight', 'encoder.layers.5.feed_forward.layer_norm.bias', 'encoder.layers.5.feed_forward.layer_norm.weight', 'encoder.layers.5.feed_forward.pwff_layer.0.bias', 'encoder.layers.5.feed_forward.pwff_layer.0.weight', 'encoder.layers.5.feed_forward.pwff_layer.3.bias', 'encoder.layers.5.feed_forward.pwff_layer.3.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.5.src_src_att.k_layer.bias', 'encoder.layers.5.src_src_att.k_layer.weight', 'encoder.layers.5.src_src_att.output_layer.bias', 'encoder.layers.5.src_src_att.output_layer.weight', 'encoder.layers.5.src_src_att.q_layer.bias', 'encoder.layers.5.src_src_att.q_layer.weight', 'encoder.layers.5.src_src_att.v_layer.bias', 'encoder.layers.5.src_src_att.v_layer.weight', 'src_embed.lut.weight']\n",
            "2019-11-28 03:28:41,838 cfg.name                           : enxh_transformer\n",
            "2019-11-28 03:28:41,838 cfg.data.src                       : en\n",
            "2019-11-28 03:28:41,838 cfg.data.trg                       : xh\n",
            "2019-11-28 03:28:41,838 cfg.data.train                     : data/enxh/train.bpe\n",
            "2019-11-28 03:28:41,838 cfg.data.dev                       : data/enxh/dev.bpe\n",
            "2019-11-28 03:28:41,838 cfg.data.test                      : data/enxh/test.bpe\n",
            "2019-11-28 03:28:41,838 cfg.data.level                     : bpe\n",
            "2019-11-28 03:28:41,838 cfg.data.lowercase                 : False\n",
            "2019-11-28 03:28:41,838 cfg.data.max_sent_length           : 100\n",
            "2019-11-28 03:28:41,838 cfg.data.src_vocab                 : data/enxh/vocab.txt\n",
            "2019-11-28 03:28:41,839 cfg.data.trg_vocab                 : data/enxh/vocab.txt\n",
            "2019-11-28 03:28:41,839 cfg.testing.beam_size              : 5\n",
            "2019-11-28 03:28:41,839 cfg.testing.alpha                  : 1.0\n",
            "2019-11-28 03:28:41,839 cfg.training.random_seed           : 42\n",
            "2019-11-28 03:28:41,839 cfg.training.optimizer             : adam\n",
            "2019-11-28 03:28:41,839 cfg.training.normalization         : tokens\n",
            "2019-11-28 03:28:41,839 cfg.training.adam_betas            : [0.9, 0.999]\n",
            "2019-11-28 03:28:41,839 cfg.training.scheduling            : plateau\n",
            "2019-11-28 03:28:41,839 cfg.training.patience              : 5\n",
            "2019-11-28 03:28:41,839 cfg.training.learning_rate_factor  : 0.5\n",
            "2019-11-28 03:28:41,839 cfg.training.learning_rate_warmup  : 1000\n",
            "2019-11-28 03:28:41,839 cfg.training.decrease_factor       : 0.7\n",
            "2019-11-28 03:28:41,839 cfg.training.loss                  : crossentropy\n",
            "2019-11-28 03:28:41,839 cfg.training.learning_rate         : 0.0003\n",
            "2019-11-28 03:28:41,840 cfg.training.learning_rate_min     : 1e-08\n",
            "2019-11-28 03:28:41,840 cfg.training.weight_decay          : 0.0\n",
            "2019-11-28 03:28:41,840 cfg.training.label_smoothing       : 0.1\n",
            "2019-11-28 03:28:41,840 cfg.training.batch_size            : 4096\n",
            "2019-11-28 03:28:41,840 cfg.training.batch_type            : token\n",
            "2019-11-28 03:28:41,840 cfg.training.eval_batch_size       : 3600\n",
            "2019-11-28 03:28:41,840 cfg.training.eval_batch_type       : token\n",
            "2019-11-28 03:28:41,840 cfg.training.batch_multiplier      : 1\n",
            "2019-11-28 03:28:41,840 cfg.training.early_stopping_metric : ppl\n",
            "2019-11-28 03:28:41,840 cfg.training.epochs                : 50\n",
            "2019-11-28 03:28:41,840 cfg.training.validation_freq       : 1000\n",
            "2019-11-28 03:28:41,841 cfg.training.logging_freq          : 100\n",
            "2019-11-28 03:28:41,841 cfg.training.eval_metric           : bleu\n",
            "2019-11-28 03:28:41,841 cfg.training.model_dir             : models/enxh_transformer\n",
            "2019-11-28 03:28:41,841 cfg.training.overwrite             : False\n",
            "2019-11-28 03:28:41,841 cfg.training.shuffle               : True\n",
            "2019-11-28 03:28:41,841 cfg.training.use_cuda              : True\n",
            "2019-11-28 03:28:41,841 cfg.training.max_output_length     : 100\n",
            "2019-11-28 03:28:41,842 cfg.training.print_valid_sents     : [0, 1, 2, 3]\n",
            "2019-11-28 03:28:41,842 cfg.training.keep_last_ckpts       : 3\n",
            "2019-11-28 03:28:41,842 cfg.model.initializer              : xavier\n",
            "2019-11-28 03:28:41,842 cfg.model.bias_initializer         : zeros\n",
            "2019-11-28 03:28:41,842 cfg.model.init_gain                : 1.0\n",
            "2019-11-28 03:28:41,842 cfg.model.embed_initializer        : xavier\n",
            "2019-11-28 03:28:41,842 cfg.model.embed_init_gain          : 1.0\n",
            "2019-11-28 03:28:41,842 cfg.model.tied_embeddings          : True\n",
            "2019-11-28 03:28:41,843 cfg.model.tied_softmax             : True\n",
            "2019-11-28 03:28:41,843 cfg.model.encoder.type             : transformer\n",
            "2019-11-28 03:28:41,843 cfg.model.encoder.num_layers       : 6\n",
            "2019-11-28 03:28:41,843 cfg.model.encoder.num_heads        : 4\n",
            "2019-11-28 03:28:41,843 cfg.model.encoder.embeddings.embedding_dim : 256\n",
            "2019-11-28 03:28:41,843 cfg.model.encoder.embeddings.scale : True\n",
            "2019-11-28 03:28:41,843 cfg.model.encoder.embeddings.dropout : 0.2\n",
            "2019-11-28 03:28:41,843 cfg.model.encoder.hidden_size      : 256\n",
            "2019-11-28 03:28:41,844 cfg.model.encoder.ff_size          : 1024\n",
            "2019-11-28 03:28:41,844 cfg.model.encoder.dropout          : 0.3\n",
            "2019-11-28 03:28:41,844 cfg.model.decoder.type             : transformer\n",
            "2019-11-28 03:28:41,844 cfg.model.decoder.num_layers       : 6\n",
            "2019-11-28 03:28:41,844 cfg.model.decoder.num_heads        : 4\n",
            "2019-11-28 03:28:41,844 cfg.model.decoder.embeddings.embedding_dim : 256\n",
            "2019-11-28 03:28:41,844 cfg.model.decoder.embeddings.scale : True\n",
            "2019-11-28 03:28:41,844 cfg.model.decoder.embeddings.dropout : 0.2\n",
            "2019-11-28 03:28:41,845 cfg.model.decoder.hidden_size      : 256\n",
            "2019-11-28 03:28:41,845 cfg.model.decoder.ff_size          : 1024\n",
            "2019-11-28 03:28:41,845 cfg.model.decoder.dropout          : 0.3\n",
            "2019-11-28 03:28:41,845 Data set sizes: \n",
            "\ttrain 805627,\n",
            "\tvalid 994,\n",
            "\ttest 2711\n",
            "2019-11-28 03:28:41,845 First training example:\n",
            "\t[SRC] How One Mar@@ ri@@ age W@@ as S@@ av@@ ed\n",
            "\t[TRG] Indlela O@@ was@@ ind@@ iswa Ng@@ ayo Lo M@@ tshato\n",
            "2019-11-28 03:28:41,845 First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) the (7) to (8) of (9) a\n",
            "2019-11-28 03:28:41,846 First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) the (7) to (8) of (9) a\n",
            "2019-11-28 03:28:41,846 Number of Src words (types): 4460\n",
            "2019-11-28 03:28:41,847 Number of Trg words (types): 4460\n",
            "2019-11-28 03:28:41,847 Model(\n",
            "\tencoder=TransformerEncoder(num_layers=6, num_heads=4),\n",
            "\tdecoder=TransformerDecoder(num_layers=6, num_heads=4),\n",
            "\tsrc_embed=Embeddings(embedding_dim=256, vocab_size=4460),\n",
            "\ttrg_embed=Embeddings(embedding_dim=256, vocab_size=4460))\n",
            "2019-11-28 03:28:41,851 EPOCH 1\n",
            "2019-11-28 03:29:15,222 Epoch   1 Step:      100 Batch Loss:     5.969117 Tokens per Sec:     7519, Lr: 0.000300\n",
            "2019-11-28 03:29:47,372 Epoch   1 Step:      200 Batch Loss:     5.835512 Tokens per Sec:     7933, Lr: 0.000300\n",
            "2019-11-28 03:30:19,306 Epoch   1 Step:      300 Batch Loss:     5.630019 Tokens per Sec:     7950, Lr: 0.000300\n",
            "2019-11-28 03:30:51,390 Epoch   1 Step:      400 Batch Loss:     5.642172 Tokens per Sec:     7914, Lr: 0.000300\n",
            "2019-11-28 03:31:23,788 Epoch   1 Step:      500 Batch Loss:     5.420583 Tokens per Sec:     7952, Lr: 0.000300\n",
            "2019-11-28 03:31:55,952 Epoch   1 Step:      600 Batch Loss:     5.189330 Tokens per Sec:     7896, Lr: 0.000300\n",
            "2019-11-28 03:32:27,923 Epoch   1 Step:      700 Batch Loss:     5.146644 Tokens per Sec:     7771, Lr: 0.000300\n",
            "2019-11-28 03:33:00,034 Epoch   1 Step:      800 Batch Loss:     4.785080 Tokens per Sec:     7693, Lr: 0.000300\n",
            "2019-11-28 03:33:32,308 Epoch   1 Step:      900 Batch Loss:     4.680697 Tokens per Sec:     7894, Lr: 0.000300\n",
            "2019-11-28 03:34:04,338 Epoch   1 Step:     1000 Batch Loss:     4.793759 Tokens per Sec:     7910, Lr: 0.000300\n",
            "2019-11-28 03:35:32,895 Hooray! New best validation result [ppl]!\n",
            "2019-11-28 03:35:32,895 Saving new checkpoint.\n",
            "2019-11-28 03:35:33,280 Example #0\n",
            "2019-11-28 03:35:33,280 \tSource:     Because we love the Bible , we also love our publications , which are based on God’s Word .\n",
            "2019-11-28 03:35:33,280 \tReference:  Ngenxa yokuba siyithanda iBhayibhile , siyazithanda neencwadi zethu , ezisekelwe kwiLizwi likaThixo .\n",
            "2019-11-28 03:35:33,280 \tHypothesis: Xa , uYehova ukuba ndenza ukuba ndenza ukuba ndenza ukuba ndenza ukuba ndenza ukuba uYehova .\n",
            "2019-11-28 03:35:33,280 Example #1\n",
            "2019-11-28 03:35:33,281 \tSource:     All the books , brochures , magazines , and other literature we receive are provisions from Jehovah .\n",
            "2019-11-28 03:35:33,281 \tReference:  Zonke iincwadi , iincwadana , iimagazini nolunye uncwadi esilufumanayo , ngamalungiselelo avela kuYehova .\n",
            "2019-11-28 03:35:33,281 \tHypothesis: Uphela , uMqula , yaye ndenza ukuba ndenza ukuba ndenza ukuba ndenza .\n",
            "2019-11-28 03:35:33,281 Example #2\n",
            "2019-11-28 03:35:33,281 \tSource:     They help us to stay close to him and to keep our faith strong . ​ — Titus 2 : 2 .\n",
            "2019-11-28 03:35:33,281 \tReference:  Zisinceda sihlale sisondelelene naye , yaye sigcine ukholo lwethu lomelele . — Tito 2 : 2 .\n",
            "2019-11-28 03:35:33,281 \tHypothesis: Ubenza ukuba ukuba ndenza ukuba ‘ kuthetha ukuba ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ Ndayayayenza .\n",
            "2019-11-28 03:35:33,281 Example #3\n",
            "2019-11-28 03:35:33,281 \tSource:     Many of our publications are written for Jehovah’s Witnesses in general .\n",
            "2019-11-28 03:35:33,281 \tReference:  Uninzi lweencwadi zethu lubhalelwe amaNgqina kaYehova .\n",
            "2019-11-28 03:35:33,282 \tHypothesis: Uphela ukuba uthetha ukuba uthetha ukuba ndenza ukuba ndenza .\n",
            "2019-11-28 03:35:33,282 Validation result (greedy) at epoch   1, step     1000: bleu:   0.00, loss: 109389.6797, ppl:  98.5547, duration: 88.9437s\n",
            "2019-11-28 03:36:05,454 Epoch   1 Step:     1100 Batch Loss:     4.432894 Tokens per Sec:     7801, Lr: 0.000300\n",
            "2019-11-28 03:36:37,558 Epoch   1 Step:     1200 Batch Loss:     4.735152 Tokens per Sec:     7863, Lr: 0.000300\n",
            "2019-11-28 03:37:09,730 Epoch   1 Step:     1300 Batch Loss:     4.645395 Tokens per Sec:     7833, Lr: 0.000300\n",
            "2019-11-28 03:37:41,763 Epoch   1 Step:     1400 Batch Loss:     4.462127 Tokens per Sec:     7795, Lr: 0.000300\n",
            "2019-11-28 03:38:14,362 Epoch   1 Step:     1500 Batch Loss:     4.427623 Tokens per Sec:     7958, Lr: 0.000300\n",
            "2019-11-28 03:38:46,697 Epoch   1 Step:     1600 Batch Loss:     4.041749 Tokens per Sec:     7929, Lr: 0.000300\n",
            "2019-11-28 03:39:18,903 Epoch   1 Step:     1700 Batch Loss:     3.948820 Tokens per Sec:     7838, Lr: 0.000300\n",
            "2019-11-28 03:39:51,220 Epoch   1 Step:     1800 Batch Loss:     3.924282 Tokens per Sec:     7842, Lr: 0.000300\n",
            "2019-11-28 03:40:23,307 Epoch   1 Step:     1900 Batch Loss:     3.684009 Tokens per Sec:     7891, Lr: 0.000300\n",
            "2019-11-28 03:40:55,374 Epoch   1 Step:     2000 Batch Loss:     3.479155 Tokens per Sec:     7889, Lr: 0.000300\n",
            "2019-11-28 03:42:23,894 Hooray! New best validation result [ppl]!\n",
            "2019-11-28 03:42:23,895 Saving new checkpoint.\n",
            "2019-11-28 03:42:24,244 Example #0\n",
            "2019-11-28 03:42:24,244 \tSource:     Because we love the Bible , we also love our publications , which are based on God’s Word .\n",
            "2019-11-28 03:42:24,245 \tReference:  Ngenxa yokuba siyithanda iBhayibhile , siyazithanda neencwadi zethu , ezisekelwe kwiLizwi likaThixo .\n",
            "2019-11-28 03:42:24,245 \tHypothesis: Ngenxa yokuba uYehova , iBhayibhile iyintoni indlela yokubonisa ngayo , iBhayibhile .\n",
            "2019-11-28 03:42:24,245 Example #1\n",
            "2019-11-28 03:42:24,245 \tSource:     All the books , brochures , magazines , and other literature we receive are provisions from Jehovah .\n",
            "2019-11-28 03:42:24,245 \tReference:  Zonke iincwadi , iincwadana , iimagazini nolunye uncwadi esilufumanayo , ngamalungiselelo avela kuYehova .\n",
            "2019-11-28 03:42:24,245 \tHypothesis: Siyintoni iincwadi , iincwadi zaseBhabhiloni , ziqhubeka ziphila .\n",
            "2019-11-28 03:42:24,245 Example #2\n",
            "2019-11-28 03:42:24,245 \tSource:     They help us to stay close to him and to keep our faith strong . ​ — Titus 2 : 2 .\n",
            "2019-11-28 03:42:24,245 \tReference:  Zisinceda sihlale sisondelelene naye , yaye sigcine ukholo lwethu lomelele . — Tito 2 : 2 .\n",
            "2019-11-28 03:42:24,245 \tHypothesis: Siyiyiyiyiyiyiyiyiyiyinyaniso . — Yakobi 2 : 1 .\n",
            "2019-11-28 03:42:24,246 Example #3\n",
            "2019-11-28 03:42:24,246 \tSource:     Many of our publications are written for Jehovah’s Witnesses in general .\n",
            "2019-11-28 03:42:24,246 \tReference:  Uninzi lweencwadi zethu lubhalelwe amaNgqina kaYehova .\n",
            "2019-11-28 03:42:24,246 \tHypothesis: Izinto zamaKristu ziqhelekileyo zamaNgqina kaYehova .\n",
            "2019-11-28 03:42:24,246 Validation result (greedy) at epoch   1, step     2000: bleu:   1.83, loss: 85190.3984, ppl:  35.6972, duration: 88.8715s\n",
            "2019-11-28 03:42:56,385 Epoch   1 Step:     2100 Batch Loss:     3.816336 Tokens per Sec:     7801, Lr: 0.000300\n",
            "2019-11-28 03:43:28,943 Epoch   1 Step:     2200 Batch Loss:     3.855640 Tokens per Sec:     7874, Lr: 0.000300\n",
            "2019-11-28 03:44:01,412 Epoch   1 Step:     2300 Batch Loss:     3.410629 Tokens per Sec:     7950, Lr: 0.000300\n",
            "2019-11-28 03:44:33,524 Epoch   1 Step:     2400 Batch Loss:     3.755902 Tokens per Sec:     7862, Lr: 0.000300\n",
            "2019-11-28 03:45:05,682 Epoch   1 Step:     2500 Batch Loss:     3.723137 Tokens per Sec:     7850, Lr: 0.000300\n",
            "2019-11-28 03:45:37,742 Epoch   1 Step:     2600 Batch Loss:     3.811719 Tokens per Sec:     7761, Lr: 0.000300\n",
            "2019-11-28 03:46:09,891 Epoch   1 Step:     2700 Batch Loss:     3.668521 Tokens per Sec:     7869, Lr: 0.000300\n",
            "2019-11-28 03:46:42,110 Epoch   1 Step:     2800 Batch Loss:     3.213022 Tokens per Sec:     7854, Lr: 0.000300\n",
            "2019-11-28 03:47:14,324 Epoch   1 Step:     2900 Batch Loss:     3.814641 Tokens per Sec:     7833, Lr: 0.000300\n",
            "2019-11-28 03:47:46,736 Epoch   1 Step:     3000 Batch Loss:     3.192456 Tokens per Sec:     7956, Lr: 0.000300\n",
            "2019-11-28 03:49:15,224 Hooray! New best validation result [ppl]!\n",
            "2019-11-28 03:49:15,225 Saving new checkpoint.\n",
            "2019-11-28 03:49:15,550 Example #0\n",
            "2019-11-28 03:49:15,551 \tSource:     Because we love the Bible , we also love our publications , which are based on God’s Word .\n",
            "2019-11-28 03:49:15,551 \tReference:  Ngenxa yokuba siyithanda iBhayibhile , siyazithanda neencwadi zethu , ezisekelwe kwiLizwi likaThixo .\n",
            "2019-11-28 03:49:15,551 \tHypothesis: Ngenxa yoko , iBhayibhile iyinyaniso , iBhayibhile iyasebenzisa imibuzo yethu , iBhayibhile .\n",
            "2019-11-28 03:49:15,551 Example #1\n",
            "2019-11-28 03:49:15,552 \tSource:     All the books , brochures , magazines , and other literature we receive are provisions from Jehovah .\n",
            "2019-11-28 03:49:15,552 \tReference:  Zonke iincwadi , iincwadana , iimagazini nolunye uncwadi esilufumanayo , ngamalungiselelo avela kuYehova .\n",
            "2019-11-28 03:49:15,552 \tHypothesis: Kukho iincwadi , iincwadi zaseKorinte , yaye zaqalisa ukufumana imibuzo yethu , yaye uYehova uyasinceda senze .\n",
            "2019-11-28 03:49:15,552 Example #2\n",
            "2019-11-28 03:49:15,552 \tSource:     They help us to stay close to him and to keep our faith strong . ​ — Titus 2 : 2 .\n",
            "2019-11-28 03:49:15,552 \tReference:  Zisinceda sihlale sisondelelene naye , yaye sigcine ukholo lwethu lomelele . — Tito 2 : 2 .\n",
            "2019-11-28 03:49:15,552 \tHypothesis: Basinceda senze senze sethu size senze senze sokholo . — Thelekisa . — 2 : 1 .\n",
            "2019-11-28 03:49:15,553 Example #3\n",
            "2019-11-28 03:49:15,553 \tSource:     Many of our publications are written for Jehovah’s Witnesses in general .\n",
            "2019-11-28 03:49:15,553 \tReference:  Uninzi lweencwadi zethu lubhalelwe amaNgqina kaYehova .\n",
            "2019-11-28 03:49:15,553 \tHypothesis: Abaninzi bethu baba namaNgqina kaYehova ayeza kukaYehova .\n",
            "2019-11-28 03:49:15,553 Validation result (greedy) at epoch   1, step     3000: bleu:   3.45, loss: 72545.0469, ppl:  20.9975, duration: 88.8169s\n",
            "2019-11-28 03:49:47,934 Epoch   1 Step:     3100 Batch Loss:     3.133117 Tokens per Sec:     7885, Lr: 0.000300\n",
            "2019-11-28 03:50:19,808 Epoch   1 Step:     3200 Batch Loss:     3.492435 Tokens per Sec:     7828, Lr: 0.000300\n",
            "2019-11-28 03:50:51,909 Epoch   1 Step:     3300 Batch Loss:     3.489009 Tokens per Sec:     7796, Lr: 0.000300\n",
            "2019-11-28 03:51:24,448 Epoch   1 Step:     3400 Batch Loss:     3.255544 Tokens per Sec:     7908, Lr: 0.000300\n",
            "2019-11-28 03:51:56,751 Epoch   1 Step:     3500 Batch Loss:     3.399981 Tokens per Sec:     7831, Lr: 0.000300\n",
            "2019-11-28 03:52:28,760 Epoch   1 Step:     3600 Batch Loss:     2.872410 Tokens per Sec:     7807, Lr: 0.000300\n",
            "2019-11-28 03:53:01,136 Epoch   1 Step:     3700 Batch Loss:     3.694872 Tokens per Sec:     7775, Lr: 0.000300\n",
            "2019-11-28 03:53:33,735 Epoch   1 Step:     3800 Batch Loss:     3.180931 Tokens per Sec:     7831, Lr: 0.000300\n",
            "2019-11-28 03:54:06,077 Epoch   1 Step:     3900 Batch Loss:     3.216292 Tokens per Sec:     7907, Lr: 0.000300\n",
            "2019-11-28 03:54:38,299 Epoch   1 Step:     4000 Batch Loss:     3.186261 Tokens per Sec:     7818, Lr: 0.000300\n",
            "2019-11-28 03:56:06,821 Hooray! New best validation result [ppl]!\n",
            "2019-11-28 03:56:06,821 Saving new checkpoint.\n",
            "2019-11-28 03:56:07,178 Example #0\n",
            "2019-11-28 03:56:07,178 \tSource:     Because we love the Bible , we also love our publications , which are based on God’s Word .\n",
            "2019-11-28 03:56:07,178 \tReference:  Ngenxa yokuba siyithanda iBhayibhile , siyazithanda neencwadi zethu , ezisekelwe kwiLizwi likaThixo .\n",
            "2019-11-28 03:56:07,178 \tHypothesis: Ngenxa yoko , iBhayibhile , sithandazela ukuba sithande , sonke iLizwi likaThixo .\n",
            "2019-11-28 03:56:07,179 Example #1\n",
            "2019-11-28 03:56:07,179 \tSource:     All the books , brochures , magazines , and other literature we receive are provisions from Jehovah .\n",
            "2019-11-28 03:56:07,179 \tReference:  Zonke iincwadi , iincwadana , iimagazini nolunye uncwadi esilufumanayo , ngamalungiselelo avela kuYehova .\n",
            "2019-11-28 03:56:07,179 \tHypothesis: Sonke iincwadi , iincwadi ezinkulu , yaye safumaneka kwezinye izigidi , yaye sonke uYehova .\n",
            "2019-11-28 03:56:07,179 Example #2\n",
            "2019-11-28 03:56:07,179 \tSource:     They help us to stay close to him and to keep our faith strong . ​ — Titus 2 : 2 .\n",
            "2019-11-28 03:56:07,179 \tReference:  Zisinceda sihlale sisondelelene naye , yaye sigcine ukholo lwethu lomelele . — Tito 2 : 2 .\n",
            "2019-11-28 03:56:07,179 \tHypothesis: Basinceda sithandaze size sithandaze size sithande ukholo lwethu . — 2 Thelekisa uTesare 2 : 2 .\n",
            "2019-11-28 03:56:07,179 Example #3\n",
            "2019-11-28 03:56:07,180 \tSource:     Many of our publications are written for Jehovah’s Witnesses in general .\n",
            "2019-11-28 03:56:07,180 \tReference:  Uninzi lweencwadi zethu lubhalelwe amaNgqina kaYehova .\n",
            "2019-11-28 03:56:07,180 \tHypothesis: Abaninzi bethu bafunda ukuthetha ngamaNgqina kaYehova .\n",
            "2019-11-28 03:56:07,180 Validation result (greedy) at epoch   1, step     4000: bleu:   6.48, loss: 64485.8555, ppl:  14.9722, duration: 88.8808s\n",
            "2019-11-28 03:56:39,380 Epoch   1 Step:     4100 Batch Loss:     3.334590 Tokens per Sec:     7807, Lr: 0.000300\n",
            "2019-11-28 03:57:11,516 Epoch   1 Step:     4200 Batch Loss:     3.248542 Tokens per Sec:     7906, Lr: 0.000300\n",
            "2019-11-28 03:57:43,831 Epoch   1 Step:     4300 Batch Loss:     3.114925 Tokens per Sec:     7798, Lr: 0.000300\n",
            "2019-11-28 03:58:16,041 Epoch   1 Step:     4400 Batch Loss:     3.118720 Tokens per Sec:     7813, Lr: 0.000300\n",
            "2019-11-28 03:58:48,029 Epoch   1 Step:     4500 Batch Loss:     2.994572 Tokens per Sec:     7803, Lr: 0.000300\n",
            "2019-11-28 03:59:20,113 Epoch   1 Step:     4600 Batch Loss:     2.742532 Tokens per Sec:     7871, Lr: 0.000300\n",
            "2019-11-28 03:59:52,255 Epoch   1 Step:     4700 Batch Loss:     3.193860 Tokens per Sec:     7814, Lr: 0.000300\n",
            "2019-11-28 04:00:24,324 Epoch   1 Step:     4800 Batch Loss:     2.843503 Tokens per Sec:     7844, Lr: 0.000300\n",
            "2019-11-28 04:00:56,569 Epoch   1 Step:     4900 Batch Loss:     3.032347 Tokens per Sec:     7903, Lr: 0.000300\n",
            "2019-11-28 04:01:28,763 Epoch   1 Step:     5000 Batch Loss:     3.523360 Tokens per Sec:     7828, Lr: 0.000300\n",
            "2019-11-28 04:02:57,288 Hooray! New best validation result [ppl]!\n",
            "2019-11-28 04:02:57,289 Saving new checkpoint.\n",
            "2019-11-28 04:02:57,625 Example #0\n",
            "2019-11-28 04:02:57,625 \tSource:     Because we love the Bible , we also love our publications , which are based on God’s Word .\n",
            "2019-11-28 04:02:57,626 \tReference:  Ngenxa yokuba siyithanda iBhayibhile , siyazithanda neencwadi zethu , ezisekelwe kwiLizwi likaThixo .\n",
            "2019-11-28 04:02:57,626 \tHypothesis: Ngenxa yokuba sithandazela iBhayibhile , sonke sonke sonke sifundisa iLizwi likaThixo .\n",
            "2019-11-28 04:02:57,626 Example #1\n",
            "2019-11-28 04:02:57,626 \tSource:     All the books , brochures , magazines , and other literature we receive are provisions from Jehovah .\n",
            "2019-11-28 04:02:57,626 \tReference:  Zonke iincwadi , iincwadana , iimagazini nolunye uncwadi esilufumanayo , ngamalungiselelo avela kuYehova .\n",
            "2019-11-28 04:02:57,626 \tHypothesis: Bonke iincwadi , izixeko zezahlukahlukeneyo , izixeko zezahlukahlukeneyo , yaye sisebenzisa izigqibo ezahlukahlukeneyo kuYehova .\n",
            "2019-11-28 04:02:57,626 Example #2\n",
            "2019-11-28 04:02:57,626 \tSource:     They help us to stay close to him and to keep our faith strong . ​ — Titus 2 : 2 .\n",
            "2019-11-28 04:02:57,626 \tReference:  Zisinceda sihlale sisondelelene naye , yaye sigcine ukholo lwethu lomelele . — Tito 2 : 2 .\n",
            "2019-11-28 04:02:57,626 \tHypothesis: Basinceda senze senze sithande size senze ukholo lwethu . — Thelekisa 2 : 2 .\n",
            "2019-11-28 04:02:57,627 Example #3\n",
            "2019-11-28 04:02:57,627 \tSource:     Many of our publications are written for Jehovah’s Witnesses in general .\n",
            "2019-11-28 04:02:57,627 \tReference:  Uninzi lweencwadi zethu lubhalelwe amaNgqina kaYehova .\n",
            "2019-11-28 04:02:57,627 \tHypothesis: Abaninzi bethu bafundisa ukuba amaNgqina kaYehova ayesebenzisa imithetho .\n",
            "2019-11-28 04:02:57,627 Validation result (greedy) at epoch   1, step     5000: bleu:   8.82, loss: 58589.8477, ppl:  11.6903, duration: 88.8636s\n",
            "2019-11-28 04:03:29,897 Epoch   1 Step:     5100 Batch Loss:     3.121396 Tokens per Sec:     7915, Lr: 0.000300\n",
            "2019-11-28 04:04:02,193 Epoch   1 Step:     5200 Batch Loss:     2.974516 Tokens per Sec:     7869, Lr: 0.000300\n",
            "2019-11-28 04:04:34,737 Epoch   1 Step:     5300 Batch Loss:     3.008830 Tokens per Sec:     7917, Lr: 0.000300\n",
            "2019-11-28 04:05:06,987 Epoch   1 Step:     5400 Batch Loss:     2.981620 Tokens per Sec:     7881, Lr: 0.000300\n",
            "2019-11-28 04:05:39,416 Epoch   1 Step:     5500 Batch Loss:     3.035349 Tokens per Sec:     7856, Lr: 0.000300\n",
            "2019-11-28 04:06:11,907 Epoch   1 Step:     5600 Batch Loss:     2.593649 Tokens per Sec:     8024, Lr: 0.000300\n",
            "2019-11-28 04:06:43,882 Epoch   1 Step:     5700 Batch Loss:     2.955665 Tokens per Sec:     7816, Lr: 0.000300\n",
            "2019-11-28 04:07:16,356 Epoch   1 Step:     5800 Batch Loss:     3.153049 Tokens per Sec:     7891, Lr: 0.000300\n",
            "2019-11-28 04:07:48,496 Epoch   1 Step:     5900 Batch Loss:     2.731127 Tokens per Sec:     7854, Lr: 0.000300\n",
            "2019-11-28 04:08:20,959 Epoch   1 Step:     6000 Batch Loss:     3.301008 Tokens per Sec:     7836, Lr: 0.000300\n",
            "2019-11-28 04:09:49,477 Hooray! New best validation result [ppl]!\n",
            "2019-11-28 04:09:49,477 Saving new checkpoint.\n",
            "2019-11-28 04:09:49,850 Example #0\n",
            "2019-11-28 04:09:49,850 \tSource:     Because we love the Bible , we also love our publications , which are based on God’s Word .\n",
            "2019-11-28 04:09:49,850 \tReference:  Ngenxa yokuba siyithanda iBhayibhile , siyazithanda neencwadi zethu , ezisekelwe kwiLizwi likaThixo .\n",
            "2019-11-28 04:09:49,851 \tHypothesis: Ngenxa yokuba siyithandazela iBhayibhile , siyamthanda izinto zethu , siyasekelwe kwiLizwi likaThixo .\n",
            "2019-11-28 04:09:49,851 Example #1\n",
            "2019-11-28 04:09:49,851 \tSource:     All the books , brochures , magazines , and other literature we receive are provisions from Jehovah .\n",
            "2019-11-28 04:09:49,851 \tReference:  Zonke iincwadi , iincwadana , iimagazini nolunye uncwadi esilufumanayo , ngamalungiselelo avela kuYehova .\n",
            "2019-11-28 04:09:49,851 \tHypothesis: Bonke iincwadi , izixeko , izixeko , neencwadi zethu , yaye sinikela izigqibo eziyenzayo kuYehova .\n",
            "2019-11-28 04:09:49,851 Example #2\n",
            "2019-11-28 04:09:49,851 \tSource:     They help us to stay close to him and to keep our faith strong . ​ — Titus 2 : 2 .\n",
            "2019-11-28 04:09:49,852 \tReference:  Zisinceda sihlale sisondelelene naye , yaye sigcine ukholo lwethu lomelele . — Tito 2 : 2 .\n",
            "2019-11-28 04:09:49,852 \tHypothesis: Basinceda sinyamezele size sinyamezele ukholo lwethu . — Tito 2 : 2 .\n",
            "2019-11-28 04:09:49,852 Example #3\n",
            "2019-11-28 04:09:49,852 \tSource:     Many of our publications are written for Jehovah’s Witnesses in general .\n",
            "2019-11-28 04:09:49,852 \tReference:  Uninzi lweencwadi zethu lubhalelwe amaNgqina kaYehova .\n",
            "2019-11-28 04:09:49,852 \tHypothesis: Abaninzi bethu bafundisa ukuba amaNgqina kaYehova ayibhalwe .\n",
            "2019-11-28 04:09:49,852 Validation result (greedy) at epoch   1, step     6000: bleu:  10.81, loss: 54578.4688, ppl:   9.8791, duration: 88.8933s\n",
            "2019-11-28 04:10:22,023 Epoch   1 Step:     6100 Batch Loss:     2.774702 Tokens per Sec:     7812, Lr: 0.000300\n",
            "2019-11-28 04:10:54,212 Epoch   1 Step:     6200 Batch Loss:     2.917819 Tokens per Sec:     7819, Lr: 0.000300\n",
            "2019-11-28 04:11:26,344 Epoch   1 Step:     6300 Batch Loss:     2.810411 Tokens per Sec:     7840, Lr: 0.000300\n",
            "2019-11-28 04:11:58,584 Epoch   1 Step:     6400 Batch Loss:     2.833480 Tokens per Sec:     7853, Lr: 0.000300\n",
            "2019-11-28 04:12:30,683 Epoch   1 Step:     6500 Batch Loss:     2.846267 Tokens per Sec:     7851, Lr: 0.000300\n",
            "2019-11-28 04:13:02,667 Epoch   1 Step:     6600 Batch Loss:     2.750438 Tokens per Sec:     7799, Lr: 0.000300\n",
            "2019-11-28 04:13:35,015 Epoch   1 Step:     6700 Batch Loss:     2.820136 Tokens per Sec:     7887, Lr: 0.000300\n",
            "2019-11-28 04:14:07,199 Epoch   1 Step:     6800 Batch Loss:     2.865840 Tokens per Sec:     7869, Lr: 0.000300\n",
            "2019-11-28 04:14:39,430 Epoch   1 Step:     6900 Batch Loss:     2.739399 Tokens per Sec:     7813, Lr: 0.000300\n",
            "2019-11-28 04:15:11,592 Epoch   1 Step:     7000 Batch Loss:     2.659536 Tokens per Sec:     7768, Lr: 0.000300\n",
            "2019-11-28 04:16:40,138 Hooray! New best validation result [ppl]!\n",
            "2019-11-28 04:16:40,138 Saving new checkpoint.\n",
            "2019-11-28 04:16:40,497 Example #0\n",
            "2019-11-28 04:16:40,498 \tSource:     Because we love the Bible , we also love our publications , which are based on God’s Word .\n",
            "2019-11-28 04:16:40,498 \tReference:  Ngenxa yokuba siyithanda iBhayibhile , siyazithanda neencwadi zethu , ezisekelwe kwiLizwi likaThixo .\n",
            "2019-11-28 04:16:40,498 \tHypothesis: Ngenxa yokuba siyithanda iBhayibhile , siyathandana nendlela esekelwe kwiLizwi likaThixo .\n",
            "2019-11-28 04:16:40,498 Example #1\n",
            "2019-11-28 04:16:40,498 \tSource:     All the books , brochures , magazines , and other literature we receive are provisions from Jehovah .\n",
            "2019-11-28 04:16:40,498 \tReference:  Zonke iincwadi , iincwadana , iimagazini nolunye uncwadi esilufumanayo , ngamalungiselelo avela kuYehova .\n",
            "2019-11-28 04:16:40,498 \tHypothesis: Zonke iincwadi , izixeko , izicawa , izindlu , yaye ezinye zifundisa uYehova .\n",
            "2019-11-28 04:16:40,498 Example #2\n",
            "2019-11-28 04:16:40,498 \tSource:     They help us to stay close to him and to keep our faith strong . ​ — Titus 2 : 2 .\n",
            "2019-11-28 04:16:40,498 \tReference:  Zisinceda sihlale sisondelelene naye , yaye sigcine ukholo lwethu lomelele . — Tito 2 : 2 .\n",
            "2019-11-28 04:16:40,499 \tHypothesis: Basinceda sibone ukuba sinyamezele ukholo lwethu . — Tito 2 : 2 .\n",
            "2019-11-28 04:16:40,499 Example #3\n",
            "2019-11-28 04:16:40,499 \tSource:     Many of our publications are written for Jehovah’s Witnesses in general .\n",
            "2019-11-28 04:16:40,499 \tReference:  Uninzi lweencwadi zethu lubhalelwe amaNgqina kaYehova .\n",
            "2019-11-28 04:16:40,499 \tHypothesis: Abaninzi bethu bafundisa izifundo zamaNgqina kaYehova .\n",
            "2019-11-28 04:16:40,499 Validation result (greedy) at epoch   1, step     7000: bleu:  12.68, loss: 51187.7930, ppl:   8.5688, duration: 88.9065s\n",
            "2019-11-28 04:17:12,704 Epoch   1 Step:     7100 Batch Loss:     2.759787 Tokens per Sec:     7797, Lr: 0.000300\n",
            "2019-11-28 04:17:44,832 Epoch   1 Step:     7200 Batch Loss:     2.531372 Tokens per Sec:     7744, Lr: 0.000300\n",
            "2019-11-28 04:18:17,199 Epoch   1 Step:     7300 Batch Loss:     3.093526 Tokens per Sec:     7995, Lr: 0.000300\n",
            "2019-11-28 04:18:49,282 Epoch   1 Step:     7400 Batch Loss:     2.869000 Tokens per Sec:     7854, Lr: 0.000300\n",
            "2019-11-28 04:19:21,140 Epoch   1 Step:     7500 Batch Loss:     2.466052 Tokens per Sec:     7778, Lr: 0.000300\n",
            "2019-11-28 04:19:53,370 Epoch   1 Step:     7600 Batch Loss:     2.824650 Tokens per Sec:     7783, Lr: 0.000300\n",
            "2019-11-28 04:20:25,864 Epoch   1 Step:     7700 Batch Loss:     2.679333 Tokens per Sec:     7832, Lr: 0.000300\n",
            "2019-11-28 04:20:57,879 Epoch   1 Step:     7800 Batch Loss:     2.869928 Tokens per Sec:     7736, Lr: 0.000300\n",
            "2019-11-28 04:21:30,164 Epoch   1 Step:     7900 Batch Loss:     2.593752 Tokens per Sec:     7844, Lr: 0.000300\n",
            "2019-11-28 04:22:02,312 Epoch   1 Step:     8000 Batch Loss:     2.305596 Tokens per Sec:     7856, Lr: 0.000300\n",
            "2019-11-28 04:23:30,844 Hooray! New best validation result [ppl]!\n",
            "2019-11-28 04:23:30,844 Saving new checkpoint.\n",
            "2019-11-28 04:23:31,200 Example #0\n",
            "2019-11-28 04:23:31,200 \tSource:     Because we love the Bible , we also love our publications , which are based on God’s Word .\n",
            "2019-11-28 04:23:31,200 \tReference:  Ngenxa yokuba siyithanda iBhayibhile , siyazithanda neencwadi zethu , ezisekelwe kwiLizwi likaThixo .\n",
            "2019-11-28 04:23:31,201 \tHypothesis: Ngenxa yokuba sithandana iBhayibhile , sithandana nendlela esizifundisa ngayo , esekelwe kwiLizwi likaThixo .\n",
            "2019-11-28 04:23:31,201 Example #1\n",
            "2019-11-28 04:23:31,201 \tSource:     All the books , brochures , magazines , and other literature we receive are provisions from Jehovah .\n",
            "2019-11-28 04:23:31,201 \tReference:  Zonke iincwadi , iincwadana , iimagazini nolunye uncwadi esilufumanayo , ngamalungiselelo avela kuYehova .\n",
            "2019-11-28 04:23:31,201 \tHypothesis: Zonke iincwadi , iincwadi , iincwadi , iincwadi , iincwadi , nezinye iincwadi zethu zifumaneka kwiindibano zamaNgqina kaYehova .\n",
            "2019-11-28 04:23:31,201 Example #2\n",
            "2019-11-28 04:23:31,201 \tSource:     They help us to stay close to him and to keep our faith strong . ​ — Titus 2 : 2 .\n",
            "2019-11-28 04:23:31,201 \tReference:  Zisinceda sihlale sisondelelene naye , yaye sigcine ukholo lwethu lomelele . — Tito 2 : 2 .\n",
            "2019-11-28 04:23:31,201 \tHypothesis: Basinceda sinyamezele kuye size sigcine ukholo lwethu . — Tito 2 : 2 .\n",
            "2019-11-28 04:23:31,202 Example #3\n",
            "2019-11-28 04:23:31,202 \tSource:     Many of our publications are written for Jehovah’s Witnesses in general .\n",
            "2019-11-28 04:23:31,202 \tReference:  Uninzi lweencwadi zethu lubhalelwe amaNgqina kaYehova .\n",
            "2019-11-28 04:23:31,202 \tHypothesis: Iimpapasho ezininzi zibhalwe ngamaNgqina kaYehova kwiindibano .\n",
            "2019-11-28 04:23:31,202 Validation result (greedy) at epoch   1, step     8000: bleu:  15.16, loss: 48583.4180, ppl:   7.6817, duration: 88.8899s\n",
            "2019-11-28 04:24:03,694 Epoch   1 Step:     8100 Batch Loss:     2.058821 Tokens per Sec:     7887, Lr: 0.000300\n",
            "2019-11-28 04:24:36,020 Epoch   1 Step:     8200 Batch Loss:     2.794713 Tokens per Sec:     7882, Lr: 0.000300\n",
            "2019-11-28 04:25:08,460 Epoch   1 Step:     8300 Batch Loss:     2.491896 Tokens per Sec:     7853, Lr: 0.000300\n",
            "2019-11-28 04:25:40,583 Epoch   1 Step:     8400 Batch Loss:     2.506928 Tokens per Sec:     7842, Lr: 0.000300\n",
            "2019-11-28 04:26:12,788 Epoch   1 Step:     8500 Batch Loss:     2.162141 Tokens per Sec:     7914, Lr: 0.000300\n",
            "2019-11-28 04:26:45,411 Epoch   1 Step:     8600 Batch Loss:     2.981222 Tokens per Sec:     7939, Lr: 0.000300\n",
            "2019-11-28 04:27:17,110 Epoch   1 Step:     8700 Batch Loss:     2.426652 Tokens per Sec:     7716, Lr: 0.000300\n",
            "2019-11-28 04:27:49,393 Epoch   1 Step:     8800 Batch Loss:     2.087021 Tokens per Sec:     7798, Lr: 0.000300\n",
            "2019-11-28 04:28:21,802 Epoch   1 Step:     8900 Batch Loss:     2.636862 Tokens per Sec:     7891, Lr: 0.000300\n",
            "2019-11-28 04:28:54,038 Epoch   1 Step:     9000 Batch Loss:     2.756231 Tokens per Sec:     7923, Lr: 0.000300\n",
            "2019-11-28 04:30:22,574 Hooray! New best validation result [ppl]!\n",
            "2019-11-28 04:30:22,575 Saving new checkpoint.\n",
            "2019-11-28 04:30:22,865 Example #0\n",
            "2019-11-28 04:30:22,865 \tSource:     Because we love the Bible , we also love our publications , which are based on God’s Word .\n",
            "2019-11-28 04:30:22,865 \tReference:  Ngenxa yokuba siyithanda iBhayibhile , siyazithanda neencwadi zethu , ezisekelwe kwiLizwi likaThixo .\n",
            "2019-11-28 04:30:22,865 \tHypothesis: Ngenxa yokuba siyathandaza iBhayibhile , siyayithanda iimpapasho zethu , esekelwe kwiLizwi likaThixo .\n",
            "2019-11-28 04:30:22,865 Example #1\n",
            "2019-11-28 04:30:22,866 \tSource:     All the books , brochures , magazines , and other literature we receive are provisions from Jehovah .\n",
            "2019-11-28 04:30:22,866 \tReference:  Zonke iincwadi , iincwadana , iimagazini nolunye uncwadi esilufumanayo , ngamalungiselelo avela kuYehova .\n",
            "2019-11-28 04:30:22,866 \tHypothesis: Zonke iincwadi , iincwadi zeziqhuba , iincwadi , yaye ezinye zininzi zininzi zona zakhiwo zivela kuYehova .\n",
            "2019-11-28 04:30:22,866 Example #2\n",
            "2019-11-28 04:30:22,866 \tSource:     They help us to stay close to him and to keep our faith strong . ​ — Titus 2 : 2 .\n",
            "2019-11-28 04:30:22,866 \tReference:  Zisinceda sihlale sisondelelene naye , yaye sigcine ukholo lwethu lomelele . — Tito 2 : 2 .\n",
            "2019-11-28 04:30:22,866 \tHypothesis: Basinceda sinyamezele kuye yaye sigcine ukholo lwethu . — Tito 2 : 2 .\n",
            "2019-11-28 04:30:22,866 Example #3\n",
            "2019-11-28 04:30:22,867 \tSource:     Many of our publications are written for Jehovah’s Witnesses in general .\n",
            "2019-11-28 04:30:22,867 \tReference:  Uninzi lweencwadi zethu lubhalelwe amaNgqina kaYehova .\n",
            "2019-11-28 04:30:22,867 \tHypothesis: Iimpapasho ezininzi zamaNgqina kaYehova zabhalwa ngamaNgqina kaYehova .\n",
            "2019-11-28 04:30:22,867 Validation result (greedy) at epoch   1, step     9000: bleu:  17.00, loss: 46185.0781, ppl:   6.9462, duration: 88.8285s\n",
            "2019-11-28 04:30:51,359 Epoch   1: total training loss 31030.42\n",
            "2019-11-28 04:30:51,360 EPOCH 2\n",
            "2019-11-28 04:30:56,396 Epoch   2 Step:     9100 Batch Loss:     2.330569 Tokens per Sec:     5930, Lr: 0.000300\n",
            "2019-11-28 04:31:28,539 Epoch   2 Step:     9200 Batch Loss:     2.483053 Tokens per Sec:     7797, Lr: 0.000300\n",
            "2019-11-28 04:32:01,075 Epoch   2 Step:     9300 Batch Loss:     2.393199 Tokens per Sec:     7924, Lr: 0.000300\n",
            "2019-11-28 04:32:33,262 Epoch   2 Step:     9400 Batch Loss:     2.230290 Tokens per Sec:     7857, Lr: 0.000300\n",
            "2019-11-28 04:33:05,612 Epoch   2 Step:     9500 Batch Loss:     2.639883 Tokens per Sec:     7856, Lr: 0.000300\n",
            "2019-11-28 04:33:38,036 Epoch   2 Step:     9600 Batch Loss:     2.651695 Tokens per Sec:     7863, Lr: 0.000300\n",
            "2019-11-28 04:34:10,495 Epoch   2 Step:     9700 Batch Loss:     2.487563 Tokens per Sec:     7862, Lr: 0.000300\n",
            "2019-11-28 04:34:42,867 Epoch   2 Step:     9800 Batch Loss:     2.232429 Tokens per Sec:     7813, Lr: 0.000300\n",
            "2019-11-28 04:35:14,933 Epoch   2 Step:     9900 Batch Loss:     2.351926 Tokens per Sec:     7908, Lr: 0.000300\n",
            "2019-11-28 04:35:47,176 Epoch   2 Step:    10000 Batch Loss:     2.603029 Tokens per Sec:     7818, Lr: 0.000300\n",
            "2019-11-28 04:37:15,717 Hooray! New best validation result [ppl]!\n",
            "2019-11-28 04:37:15,717 Saving new checkpoint.\n",
            "2019-11-28 04:37:16,072 Example #0\n",
            "2019-11-28 04:37:16,073 \tSource:     Because we love the Bible , we also love our publications , which are based on God’s Word .\n",
            "2019-11-28 04:37:16,073 \tReference:  Ngenxa yokuba siyithanda iBhayibhile , siyazithanda neencwadi zethu , ezisekelwe kwiLizwi likaThixo .\n",
            "2019-11-28 04:37:16,073 \tHypothesis: Ngenxa yokuba sithande iBhayibhile , sithande iimpapasho zethu , esekelwe kwiLizwi likaThixo .\n",
            "2019-11-28 04:37:16,073 Example #1\n",
            "2019-11-28 04:37:16,073 \tSource:     All the books , brochures , magazines , and other literature we receive are provisions from Jehovah .\n",
            "2019-11-28 04:37:16,073 \tReference:  Zonke iincwadi , iincwadana , iimagazini nolunye uncwadi esilufumanayo , ngamalungiselelo avela kuYehova .\n",
            "2019-11-28 04:37:16,073 \tHypothesis: Zonke iincwadi , izixhobo , izindlu , izigidi , nezinye izinto ezifumaneka ngazo uYehova .\n",
            "2019-11-28 04:37:16,073 Example #2\n",
            "2019-11-28 04:37:16,074 \tSource:     They help us to stay close to him and to keep our faith strong . ​ — Titus 2 : 2 .\n",
            "2019-11-28 04:37:16,074 \tReference:  Zisinceda sihlale sisondelelene naye , yaye sigcine ukholo lwethu lomelele . — Tito 2 : 2 .\n",
            "2019-11-28 04:37:16,074 \tHypothesis: Basinceda sihlale sinyanzelekile yaye basondele ukholo lwethu . — Tito 2 : 2 .\n",
            "2019-11-28 04:37:16,074 Example #3\n",
            "2019-11-28 04:37:16,074 \tSource:     Many of our publications are written for Jehovah’s Witnesses in general .\n",
            "2019-11-28 04:37:16,074 \tReference:  Uninzi lweencwadi zethu lubhalelwe amaNgqina kaYehova .\n",
            "2019-11-28 04:37:16,074 \tHypothesis: Iimpapasho ezininzi zibhalwe amaNgqina kaYehova ezizukulwana .\n",
            "2019-11-28 04:37:16,074 Validation result (greedy) at epoch   2, step    10000: bleu:  17.63, loss: 44616.5352, ppl:   6.5036, duration: 88.8980s\n",
            "2019-11-28 04:37:48,275 Epoch   2 Step:    10100 Batch Loss:     2.712292 Tokens per Sec:     7878, Lr: 0.000300\n",
            "2019-11-28 04:38:20,503 Epoch   2 Step:    10200 Batch Loss:     2.286560 Tokens per Sec:     7795, Lr: 0.000300\n",
            "2019-11-28 04:38:52,510 Epoch   2 Step:    10300 Batch Loss:     2.453007 Tokens per Sec:     7816, Lr: 0.000300\n",
            "2019-11-28 04:39:24,779 Epoch   2 Step:    10400 Batch Loss:     2.608026 Tokens per Sec:     7936, Lr: 0.000300\n",
            "2019-11-28 04:39:57,187 Epoch   2 Step:    10500 Batch Loss:     2.344222 Tokens per Sec:     7928, Lr: 0.000300\n",
            "2019-11-28 04:40:29,347 Epoch   2 Step:    10600 Batch Loss:     2.278925 Tokens per Sec:     7851, Lr: 0.000300\n",
            "2019-11-28 04:41:01,642 Epoch   2 Step:    10700 Batch Loss:     2.448336 Tokens per Sec:     7867, Lr: 0.000300\n",
            "2019-11-28 04:41:34,150 Epoch   2 Step:    10800 Batch Loss:     2.259028 Tokens per Sec:     7924, Lr: 0.000300\n",
            "2019-11-28 04:42:06,544 Epoch   2 Step:    10900 Batch Loss:     2.292706 Tokens per Sec:     7947, Lr: 0.000300\n",
            "2019-11-28 04:42:38,519 Epoch   2 Step:    11000 Batch Loss:     2.446060 Tokens per Sec:     7843, Lr: 0.000300\n",
            "2019-11-28 04:44:06,986 Hooray! New best validation result [ppl]!\n",
            "2019-11-28 04:44:06,986 Saving new checkpoint.\n",
            "2019-11-28 04:44:07,274 Example #0\n",
            "2019-11-28 04:44:07,275 \tSource:     Because we love the Bible , we also love our publications , which are based on God’s Word .\n",
            "2019-11-28 04:44:07,275 \tReference:  Ngenxa yokuba siyithanda iBhayibhile , siyazithanda neencwadi zethu , ezisekelwe kwiLizwi likaThixo .\n",
            "2019-11-28 04:44:07,275 \tHypothesis: Ngenxa yokuba siyithanda iBhayibhile , siyayithanda imibuzo yethu , esekelwe kwiLizwi likaThixo .\n",
            "2019-11-28 04:44:07,275 Example #1\n",
            "2019-11-28 04:44:07,275 \tSource:     All the books , brochures , magazines , and other literature we receive are provisions from Jehovah .\n",
            "2019-11-28 04:44:07,275 \tReference:  Zonke iincwadi , iincwadana , iimagazini nolunye uncwadi esilufumanayo , ngamalungiselelo avela kuYehova .\n",
            "2019-11-28 04:44:07,275 \tHypothesis: Zonke iincwadi , iincwadi , imithi , imithi , yaye ezinye iincwadi zethu zifumaneka kwilungiselelo likaYehova .\n",
            "2019-11-28 04:44:07,275 Example #2\n",
            "2019-11-28 04:44:07,275 \tSource:     They help us to stay close to him and to keep our faith strong . ​ — Titus 2 : 2 .\n",
            "2019-11-28 04:44:07,275 \tReference:  Zisinceda sihlale sisondelelene naye , yaye sigcine ukholo lwethu lomelele . — Tito 2 : 2 .\n",
            "2019-11-28 04:44:07,275 \tHypothesis: Basinceda sinyamezele kuye size sihlale sinokholo olomeleleyo . — Tito 2 : 2 .\n",
            "2019-11-28 04:44:07,276 Example #3\n",
            "2019-11-28 04:44:07,276 \tSource:     Many of our publications are written for Jehovah’s Witnesses in general .\n",
            "2019-11-28 04:44:07,276 \tReference:  Uninzi lweencwadi zethu lubhalelwe amaNgqina kaYehova .\n",
            "2019-11-28 04:44:07,276 \tHypothesis: Iimpapasho ezininzi zibhalwe ngamaNgqina kaYehova .\n",
            "2019-11-28 04:44:07,276 Validation result (greedy) at epoch   2, step    11000: bleu:  18.49, loss: 43299.8906, ppl:   6.1540, duration: 88.7564s\n",
            "2019-11-28 04:44:39,642 Epoch   2 Step:    11100 Batch Loss:     2.380375 Tokens per Sec:     7862, Lr: 0.000300\n",
            "2019-11-28 04:45:11,708 Epoch   2 Step:    11200 Batch Loss:     2.530085 Tokens per Sec:     7840, Lr: 0.000300\n",
            "2019-11-28 04:45:44,348 Epoch   2 Step:    11300 Batch Loss:     1.949957 Tokens per Sec:     8025, Lr: 0.000300\n",
            "2019-11-28 04:46:16,339 Epoch   2 Step:    11400 Batch Loss:     2.102463 Tokens per Sec:     7912, Lr: 0.000300\n",
            "2019-11-28 04:46:48,595 Epoch   2 Step:    11500 Batch Loss:     2.365344 Tokens per Sec:     7777, Lr: 0.000300\n",
            "2019-11-28 04:47:20,887 Epoch   2 Step:    11600 Batch Loss:     2.324276 Tokens per Sec:     7866, Lr: 0.000300\n",
            "2019-11-28 04:47:53,320 Epoch   2 Step:    11700 Batch Loss:     2.139009 Tokens per Sec:     7914, Lr: 0.000300\n",
            "2019-11-28 04:48:25,530 Epoch   2 Step:    11800 Batch Loss:     2.445348 Tokens per Sec:     7922, Lr: 0.000300\n",
            "2019-11-28 04:48:57,815 Epoch   2 Step:    11900 Batch Loss:     2.418062 Tokens per Sec:     7847, Lr: 0.000300\n",
            "2019-11-28 04:49:30,170 Epoch   2 Step:    12000 Batch Loss:     2.435956 Tokens per Sec:     7857, Lr: 0.000300\n",
            "2019-11-28 04:50:58,600 Hooray! New best validation result [ppl]!\n",
            "2019-11-28 04:50:58,600 Saving new checkpoint.\n",
            "2019-11-28 04:50:58,903 Example #0\n",
            "2019-11-28 04:50:58,903 \tSource:     Because we love the Bible , we also love our publications , which are based on God’s Word .\n",
            "2019-11-28 04:50:58,903 \tReference:  Ngenxa yokuba siyithanda iBhayibhile , siyazithanda neencwadi zethu , ezisekelwe kwiLizwi likaThixo .\n",
            "2019-11-28 04:50:58,903 \tHypothesis: Ngenxa yokuba siyathandaza iBhayibhile , siyayithanda iimpapasho zethu , esekelwe kwiLizwi likaThixo .\n",
            "2019-11-28 04:50:58,903 Example #1\n",
            "2019-11-28 04:50:58,904 \tSource:     All the books , brochures , magazines , and other literature we receive are provisions from Jehovah .\n",
            "2019-11-28 04:50:58,904 \tReference:  Zonke iincwadi , iincwadana , iimagazini nolunye uncwadi esilufumanayo , ngamalungiselelo avela kuYehova .\n",
            "2019-11-28 04:50:58,904 \tHypothesis: Zonke iincwadi , iincwadi , amaphephancwadi , amaphephancwadi nezinye iingxelo zethu zifumaneka kumalungiselelo kaYehova .\n",
            "2019-11-28 04:50:58,904 Example #2\n",
            "2019-11-28 04:50:58,904 \tSource:     They help us to stay close to him and to keep our faith strong . ​ — Titus 2 : 2 .\n",
            "2019-11-28 04:50:58,904 \tReference:  Zisinceda sihlale sisondelelene naye , yaye sigcine ukholo lwethu lomelele . — Tito 2 : 2 .\n",
            "2019-11-28 04:50:58,904 \tHypothesis: Basinceda sinyamezele kuye size sigcine ukholo lwethu . — Titus 2 : 2 .\n",
            "2019-11-28 04:50:58,904 Example #3\n",
            "2019-11-28 04:50:58,904 \tSource:     Many of our publications are written for Jehovah’s Witnesses in general .\n",
            "2019-11-28 04:50:58,904 \tReference:  Uninzi lweencwadi zethu lubhalelwe amaNgqina kaYehova .\n",
            "2019-11-28 04:50:58,904 \tHypothesis: Iimpapasho ezininzi zibhalwe ngamaNgqina kaYehova kwizizukulwana .\n",
            "2019-11-28 04:50:58,905 Validation result (greedy) at epoch   2, step    12000: bleu:  19.22, loss: 41981.7422, ppl:   5.8229, duration: 88.7338s\n",
            "2019-11-28 04:51:31,186 Epoch   2 Step:    12100 Batch Loss:     2.291575 Tokens per Sec:     7851, Lr: 0.000300\n",
            "2019-11-28 04:52:03,545 Epoch   2 Step:    12200 Batch Loss:     2.317878 Tokens per Sec:     7979, Lr: 0.000300\n",
            "2019-11-28 04:52:35,987 Epoch   2 Step:    12300 Batch Loss:     2.419537 Tokens per Sec:     7888, Lr: 0.000300\n",
            "2019-11-28 04:53:08,000 Epoch   2 Step:    12400 Batch Loss:     2.386891 Tokens per Sec:     7822, Lr: 0.000300\n",
            "2019-11-28 04:53:40,333 Epoch   2 Step:    12500 Batch Loss:     2.379983 Tokens per Sec:     7887, Lr: 0.000300\n",
            "2019-11-28 04:54:12,647 Epoch   2 Step:    12600 Batch Loss:     2.197493 Tokens per Sec:     7852, Lr: 0.000300\n",
            "2019-11-28 04:54:45,033 Epoch   2 Step:    12700 Batch Loss:     2.006970 Tokens per Sec:     7929, Lr: 0.000300\n",
            "2019-11-28 04:55:17,177 Epoch   2 Step:    12800 Batch Loss:     2.314119 Tokens per Sec:     7859, Lr: 0.000300\n",
            "2019-11-28 04:55:49,732 Epoch   2 Step:    12900 Batch Loss:     1.859855 Tokens per Sec:     7960, Lr: 0.000300\n",
            "2019-11-28 04:56:22,025 Epoch   2 Step:    13000 Batch Loss:     2.368685 Tokens per Sec:     7870, Lr: 0.000300\n",
            "2019-11-28 04:57:50,486 Hooray! New best validation result [ppl]!\n",
            "2019-11-28 04:57:50,486 Saving new checkpoint.\n",
            "2019-11-28 04:57:50,787 Example #0\n",
            "2019-11-28 04:57:50,787 \tSource:     Because we love the Bible , we also love our publications , which are based on God’s Word .\n",
            "2019-11-28 04:57:50,787 \tReference:  Ngenxa yokuba siyithanda iBhayibhile , siyazithanda neencwadi zethu , ezisekelwe kwiLizwi likaThixo .\n",
            "2019-11-28 04:57:50,787 \tHypothesis: Ngenxa yokuba siyathandana iBhayibhile , siyayithanda iimpapasho zethu , esekelwe kwiLizwi likaThixo .\n",
            "2019-11-28 04:57:50,787 Example #1\n",
            "2019-11-28 04:57:50,788 \tSource:     All the books , brochures , magazines , and other literature we receive are provisions from Jehovah .\n",
            "2019-11-28 04:57:50,788 \tReference:  Zonke iincwadi , iincwadana , iimagazini nolunye uncwadi esilufumanayo , ngamalungiselelo avela kuYehova .\n",
            "2019-11-28 04:57:50,788 \tHypothesis: Zonke iincwadi , iincwadi , iincwadi , amaphephancwadi , nezinye iincwadi zethu zifumaneka kuYehova .\n",
            "2019-11-28 04:57:50,788 Example #2\n",
            "2019-11-28 04:57:50,788 \tSource:     They help us to stay close to him and to keep our faith strong . ​ — Titus 2 : 2 .\n",
            "2019-11-28 04:57:50,788 \tReference:  Zisinceda sihlale sisondelelene naye , yaye sigcine ukholo lwethu lomelele . — Tito 2 : 2 .\n",
            "2019-11-28 04:57:50,788 \tHypothesis: Basinceda sinyamezele kuye size siqhubeke sinokholo olomeleleyo . — Tito 2 : 2 .\n",
            "2019-11-28 04:57:50,788 Example #3\n",
            "2019-11-28 04:57:50,788 \tSource:     Many of our publications are written for Jehovah’s Witnesses in general .\n",
            "2019-11-28 04:57:50,788 \tReference:  Uninzi lweencwadi zethu lubhalelwe amaNgqina kaYehova .\n",
            "2019-11-28 04:57:50,788 \tHypothesis: Iimpapasho ezininzi zibhalwa ngamaNgqina kaYehova ezisizukulwana .\n",
            "2019-11-28 04:57:50,789 Validation result (greedy) at epoch   2, step    13000: bleu:  19.62, loss: 40915.3242, ppl:   5.5680, duration: 88.7635s\n",
            "2019-11-28 04:58:22,664 Epoch   2 Step:    13100 Batch Loss:     2.521534 Tokens per Sec:     7793, Lr: 0.000300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MBoDS09JM807",
        "colab": {}
      },
      "source": [
        "# Copy the created models from the notebook storage to google drive for persistant storage \n",
        "!mkdir -p \"$gdrive_path/models/${src}${tgt}_transformer/\" # Herman\n",
        "!cp -r joeynmt/models/${src}${tgt}_transformer/* \"$gdrive_path/models/${src}${tgt}_transformer/\"\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n94wlrCjVc17",
        "colab": {}
      },
      "source": [
        "# Output our validation accuracy\n",
        "! cat \"$gdrive_path/models/${src}${tgt}_transformer/validations.txt\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "66WhRE9lIhoD",
        "colab": {}
      },
      "source": [
        "# Test our model\n",
        "! cd joeynmt; python3 -m joeynmt test \"$gdrive_path/models/${src}${tgt}_transformer/config.yaml\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-siqoiGUCSb3",
        "colab_type": "text"
      },
      "source": [
        "# Plot Perplexity and Bleu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVBsmFXWqOhM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Plot Perplexity\n",
        "! python3 joeynmt/scripts/plot_validations.py \"$gdrive_path/models/${src}${tgt}_transformer\" \\\n",
        "--plot_values PPL \\\n",
        "--output_path \"$gdrive_path/models/${src}${tgt}_transformer/ppl.png\"\n",
        "\n",
        "# from IPython.display import Image\n",
        "from IPython.display import Image, display\n",
        "display(Image(\"$gdrive_path/models/${src}${tgt}_transformer/ppl.png\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "baY2MU9-Q9Pg",
        "colab": {}
      },
      "source": [
        "#Plot Bleu Score \n",
        "! python3 joeynmt/scripts/plot_validations.py \"$gdrive_path/models/${src}${tgt}_transformer\" \\\n",
        "--plot_values bleu \\\n",
        "--output_path \"$gdrive_path/models/${src}${tgt}_transformer\"/bleu.png\n",
        "\n",
        "# from IPython.display import Image\n",
        "from IPython.display import Image, display\n",
        "display(Image(\"$gdrive_path/models/${src}${tgt}_transformer/bleu.png\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBD9-C0hLcTk",
        "colab_type": "text"
      },
      "source": [
        "# Copy model from virtual drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUj6Y92cnL0-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Remove Afterwards\n",
        "# !cp -r \"/content/drive/My Drive/masakhane/en-yo-baseline/\" /content/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ug5s55svCD6c",
        "colab_type": "text"
      },
      "source": [
        "# NMT Attention Alignment Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vbqZoYkBGLZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Install keras attention\n",
        "# ! cd content;\n",
        "# ! git clone https://github.com/thushv89/attention_keras.git\n",
        "# ! cd /content/attention_keras;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AvxY4ViFUW6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ! cd /content;\n",
        "# ! git clone https://github.com/M4t1ss/SoftAlignments.git\n",
        "\n",
        "https://github.com/zhaocq-nlp/Attention-Visualization\n",
        "https://github.com/shreydesai/attention-viz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQGu-sh1J-wl",
        "colab_type": "text"
      },
      "source": [
        "##vizseq"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dpk3VmQFZFuB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install vizseq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTaK58U2ZVeU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install -U tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2ADsvf3TBYy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip3 install -U nltk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xhqKjIdSmST",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import vizseq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EP-50OnOWQUy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from glob import glob\n",
        "root = '/content/drive/My Drive/Colab Notebooks/MyJoeyNMT'\n",
        "src, ref, hypo = glob(f'{root}/navy_xhen/word/test.xh'), glob(f'{root}/navy_xhen/word/test.en'), glob(f'{root}/models/transformer_xhen/predictions.test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpR9I9hsWa7p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#First, load the vizseq package:\n",
        "vizseq.view_stats(src, ref)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9WfWTxfbkSI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vizseq.view_n_grams(src)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXP0IexPb-6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To view corpus-level scores (BLEU and METEOR):\n",
        "vizseq.view_scores(ref, hypo, ['bleu', 'meteor'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTq0t_5Zcnae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vizseq.available_scorers()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6teATKHgcrcs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import vizseq.VizSeqSortingType\n",
        "vizseq.view_examples(src, ref, hypo, ['bleu', 'meteor'], page_sz=2, page_no=12)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yE42J1DeM6p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Google Translate Integration\n",
        "vizseq.set_google_credential_path('path to google credential json file')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HS-80RQeUeU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vizseq.view_examples(src, ref, hypo, ['bleu'], need_g_translate=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPKokpOBepzf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from vizseq.ipynb import fairseq_viz as vizseq_fs\n",
        "log_path = 'examples/data/wmt14_fr_en_test.fairseq_generate.log'\n",
        "vizseq_fs.view_stats(log_path)\n",
        "vizseq_fs.view_examples(log_path, ['bleu', 'meteor'], need_g_translate=True)\n",
        "vizseq_fs.view_scores(log_path, ['bleu', 'meteor'])\n",
        "vizseq_fs.view_n_grams(log_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUXnkaCrh7Gi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "https://docs.dgl.ai/en/latest/tutorials/models/4_old_wines/7_transformer.html"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwVv2tqwh7zb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "https://ronxin.github.io/wevi/\n",
        "https://vcg.seas.harvard.edu/publications/seq2seq-vis-a-visual-debugging-tool-for-sequence-to-sequence-models"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}